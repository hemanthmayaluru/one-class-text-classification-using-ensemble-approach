{"title": "Saliency Inspired Quality Assessment of Stereoscopic 3D Video", "tag": "eess", "abstract": " To study the visual attentional behavior of Human Visual System (HVS) on 3D content, eye tracking experiments are performed and Visual Attention Models (VAMs) are designed. One of the main applications of these VAMs is in quality assessment of 3D video. The usage of 2D VAMs in designing 2D quality metrics is already well explored. This paper investigates the added value of incorporating 3D VAMs into Full-Reference (FR) and No-Reference (NR) quality assessment metrics for stereoscopic 3D video. To this end, state-of-the-art 3D VAMs are integrated to quality assessment pipeline of various existing FR and NR stereoscopic video quality metrics. Performance evaluations using a large scale database of stereoscopic videos with various types of distortions demonstrated that using saliency maps generally improves the performance of the quality assessment task for stereoscopic video. However, depending on the type of distortion, utilized metric, and VAM, the amount of improvement will change. ", "text": "abstract study visual attentional behavior human visual system content tracking experiments performed visual attention models designed. main applications vams quality assessment video. usage vams designing quality metrics already well explored. paper investigates added value incorporating vams full-reference no-reference quality assessment metrics stereoscopic video. state-of-the-art vams integrated quality assessment pipeline various existing stereoscopic video quality metrics. performance evaluations using large scale database stereoscopic videos various types distortions demonstrated using saliency maps generally improves performance quality assessment task stereoscopic video. however depending type distortion utilized metric amount improvement change. video technologies entered consumer market past several years. technologies affected specialized target areas entertainment education medical imaging also changed quality viewing experience average consumer bringing life-like video gaming theater mobile phones television therefore crucial video content creation delivery design providing end-users highest possible quality experience. ultimate assess delivered quality subjective experiments time consuming expensive. alternative solution develop objective quality metrics attempt model human visual system measure perceptual quality. considering quality assessment metrics systems model human visual system would naturally make sense quality metrics take consideration visual attention models considering likelihood image/video regions looked viewers. visual attention models imitate predicting gazed points estimating likelihood region image draw attention. vams therefore diverse range application image video compression object recognition detection visual search retargeting retrieval quality assessment image matching segmentation figure-ground separation applications particular importance vams design quality metrics guide quality assessment techniques towards salient regions image video. then quality metrics treat visible distortions salient regions differently ones existing non-salient regions designing vams video goes back decades applications well explored saliency measurement already integrated various full-reference no-reference video quality metrics. however since video technologies entered consumer market past years existing literature vams applications complete case. consequently application vams designing video quality metrics needs addressed. makes sense considering fact quality measurement techniques usually calculate amount local visible distortions similarities image statistics perform pooling generate final metric value. saliency maps resulted vams integrated quality assessment pipeline pooling stage emphasizing salient regions content. order integrate saliency prediction full-reference stereoscopic quality assessment task zhang proposed saliency weighting factor structural similarity index depth image based rendering applications method saliency modeled average image saliency saliency resulted depth map. another work saliency extracted using used weighting factor quality metric design jiang used spectral residual along method foreground work partly supported natural sciences engineering research council canada grant stpgp institute computing information cognitive systems ubc. background depth maps saliency prediction stereoscopic images. used hard-threshold value depth split foreground background depth combined maps result saliency major drawback mentioned approaches vams used saliency measurement content experiments shown vams fail accurately predict human visual saliency addition using vams methods mentioned take consideration temporal aspects video solely based single image quality assessment. case no-reference stereoscopic video quality assessment proposed saliency term formulation sharpness metric term defined linear correlation saliency maps views. another work sohn no-reference quality assessment method stereoscopic images proposed modeling binocular quality perception context blurriness blockiness method gbvs used saliency evaluations. metrics proposed sohn using visual attention models predict saliency stereoscopic content. mentioned proven vams lack accuracy saliency prediction data. moreover metrics designed quality assessment stereoscopic images consider temporal aspects quality evaluation. explained still lack saliency based quality metrics specifically stereoscopic videos. existing methods mostly based using image saliency maps take consideration temporal aspects video saliency quality. primary question study seeks answer whether saliency predictions video vams used improve performance full-reference no-reference quality assessment stereoscopic video not. moreover interested know case performance improvements much gain achieved metric vam? potential improvements dependent type distortion assess? answer questions paper propose vams quality evaluation video cases. integrate previously designed learning based visual saliency prediction model stereoscopic video various state-of-the-art video quality metrics. evaluate added value incorporating vams quality assessment stereoscopic video using large scale database stereoscopic videos participants. main contributions paper summarized follows integrating saliency prediction maps different vams full-reference no-reference existing quality metrics. depending design metric saliency integration performed either spatial frequency domain basically means formulation metric uniquely updated treats salient regions videos differently non-salient areas. done comparing quality assessment performance metrics without saliency integration validation large scale stereoscopic video dataset reference videos different kinds rest paper organized follows section describes saliency integration methodology section contains details regarding experiments section provides results section concludes paper. video quality metrics perform quality assessment task measuring similarities distortion densities partitions video combining local partition measurements overall quality index process known pooling. quality pooling done spatially temporally therefore possible types metrics incorporate saliency prediction results pooling stage quality assessment pipeline. fig. shows proposed saliency integration scenario. rest section elaborates utilized vams various quality metrics used experiments integrate saliency detection results quality metric. learning based visual saliency previous work designed learning based visual saliency prediction model attention stereoscopic video. model takes consideration low-level stimulus driven saliency features depth motion brightness texture color well high-level context dependent attributes presence humans text vehicles animals horizon. addition effects object size compactness sparsity frame rate stereoscopic video visual discomfort taken account. tracking experiments showed lbvsd close correlation human fixation data block-diagram lbvsd depicted fig. observed fig. lowlevel high-level features integrated within learning frame work train ensemble random forests predict video saliency. details regarding lbvsd found fig. demonstrates example saliency detection integration saliency maps quality metrics visual attention models provide saliency frame video. able saliency prediction results video quality assessment consider video quality metrics produce similarities distortions transform coefficients errors general ones possible apply saliency maps weighting masks. note case quality evaluation saliency maps generated using reference stereo pair. paper integrate lbvsd following quality metrics phvsd phsd q_shao flosimd addition follow considered common practice quality evaluation using psnr ssim ms-ssim metric integration. case metrics overall quality resulted averaging frame qualities views. rest subsection elaborates saliency integration various metrics. pixel coordinates denotes frame number reference distorted frames normalized saliency denote spatial temporal mean operators respectively. note psnr calculated left right views separately average psnr considered stereo pair. ms-ssim multi-scale ssim evaluates structural distortions pair reference-distorted images number scales order apply saliency prediction ms-ssim generate saliency maps scale independently. saliency inspired msssim evaluated follows assess luminance contrast structural distortions scale generated saliency scale number decomposition scales. since ms-ssim metric saliency based ms-ssim evaluated view separately average calculated overall index. modeled full-reference stereo quality combination disparity quality quality views. used mean absolute differences measure changes disparity ssim view quality measurement order modify metric according saliency values apply saliency weighting factor disparity view quality evaluations chen proposed quality assessment framework stereo images based generating cyclopean view pictures reference distorted views. then overall quality evaluated ssim cyclopean pictures reference distorted pairs. saliency inspired formulated metric improved version phvsd considers depth maps conjunction block structures modification phsd levels block structures depth maps formulated shao colleagues proposed quality assessment method stereo images based image regions classification. method view partitioned three possible categories nonorresponding binocular fusion binocular suppression regions. three quality components calculated based three regions combined overall index follows weighting coefficients quality component. component computed average per-pixel values corresponding region. saliency information therefore incorporated components weighting factor emphasize visually important image regions. cyclopean-view model matching block pair reference view xc'i cyclopean-view model matching block pair distorted view idct stands inverse discrete cosine transform total number blocks view constant exponents local variance block disparity reference view. order incorporate saliency information three quality components saliency based ssims index first component vifs index second component. third component single average saliency value block used weight variance term. constant parameter values used ones reported flosimd flosimd exploits video quality combining temporal spatial depth quality attributes followed pooling fl-r i-th left right view frames) computed measuring strategy. temporal component dissimilarity measure corresponding views frames. depth component dissimilarity measure corresponding depth maps. flosimd formulated follows total number frames. order integrate saliency maps formulation flosimd apply masks spatial depth components metric. components utilize ms-ssim leverage already integrated ms-ssim section ii.b. follow methodology here. saliency maps applied ms-ssim depth spatial components flosimds metric consider saliency weights quality measurements. integration saliency maps quality metrics reference quality assessment generally much difficult task full reference quality assessment information available reference data. consequence quality metrics usually evaluating quality specific type distortion present. widespread application image video compression many quality metrics proposed assess sharpness blurriness blockiness images videos. compared video quality metrics less number metrics proposed literature. here nospdm q_ryu saliency integration metrics modified according available saliency maps. addition metrics also apply saliency several metrics include iqvg gbim nrpbm q_blur_farias q_block_farias q_sadaka vqsm case metrics overall quality measured average quality frames views. note case quality assessment saliency maps generated using distorted stereo pair reference available. requires accurate saliency prediction distorted videos. lbvsd capable efficiently detect salient regions video even presence distortions. fig. demonstrates examples distorted video frames saliency maps extracted using lbvsd. rest sub-section elaborates saliency integration metric. image quality index based visual saliency guided sampling gabor filtering iqvg performs blind quality assessment images applying support vector regression features extracted sampled image patches patches selected based saliency information. here swap saliency maps used iqvg stereo saliency maps lbvsd. rest process remains unchanged. roffet proposed blurriness metric images based average horizontal vertical block edge differences reference distorted pictures saliency values weights differences towards overall index follows farias akamine proposed metrics quality assessment images. metrics measure blockiness blurriness image approach blurriness metric defined average edge width. blockiness metric defined average horizontal vertical differences. saliency based versions mentioned metrics formulated follows indicates amount perceived blur region here substitute image saliency maps used video saliency maps proven provide superior stereo saliency detection anisotropy quality index blind image quality metric based measuring variance expected entropy image upon predefined directions incorporate saliency probabilities pixels entropy used index weighting coefficients. video quality metric stereoscopic images designed assess transmission artifacts method first hard threshold applied disparity maps reference distorted pair disparity values smaller threshold zero. then disparity index frame defined constant parameters blockiness across horizontal vertical edges average absolute difference in-block image samples horizontal vertical directions horizontal vertical zero crossing rates saliency information qjpeg terms views three components weights pixel values zero crossings. sohn proposed quality metric stereoscopic images takes account blurriness blockiness image pair approach pair blurriness blockiness maps generated view combined saliency maps generated views. substitute saliency maps used approach saliency maps. ar-plus thresholding no-reference blind quality metric designed quality assessment synthesized dibr images. computes binary maps measuring geometrical non-geometrical natural image distortions. generate geometric binary distortion already incorporates saliency maps thresholding operation extract salient regions. overall metric formulated follows pixel index number pixels image constant used stability minkowski exponent. integrate saliency substituting saliency maps maps already used. implementation parameters selected based information provided paper. modify quality metrics described section using stereo saliency information evaluate performance modified metrics comparison original metrics. section reviews incorporated video database experiments well subjective tests procedure. sixteen stereo videos chosen three different datasets subjective experiments. videos taken from sequences provided mpeg video compression standardization activities. sequences originally captured multi views. select views according mpeg recommendations subjective tests video compression studies digital multimedia stereo video sequences university british columbia test videos used table contains description stereo video database used experiments. introducing video databases common practice measure spatial temporal complexity videos database ensure videos dynamic scenes wide range spatial temporal complexity fig. shows distribution video database used experiments. observed fig. videos cover wide range temporal spatial complexities. addition spatial temporal video complexities depth bracket scenes measured reported table depth bracket rough estimate distance closest farthest visually important objects scene since camera information available sequences disparity maps first converted depth maps using method reported depth differences measured. visually important objects selected based available saliency maps. order evaluate performance various quality metrics several different types distortions artifacts simulated video database. table contains details regarding distortions. details found note applying distortions disparity generated stereo video using mpeg depth estimation reference software also capturing artifacts window violation vertical parallax depth plane curvature keystone distortion shear distortion considered. using different distortions reference videos resulted stereo videos database. subjective tests subjective experiments conducted using stereo video database participation subjects. test material presented viewers using passive glasses. video presentation performed using single stimulus method accordance details regarding subjective tests found study saliency maps lbvsd incorporated formulation fullreference no-reference objective quality metrics. order understand impact saliency integration performance metrics need evaluate performance without saliency integration. subjective evaluations performed measure performance objective metrics without saliency information. following common practice quality assessment literature measure metrics performances using rmse objective measures. section elaborates specifics process. collecting subjective quality scores overall mean opinion score calculated averaging individual subjective scores removing outliers objective metric value also computed using metrics compare subjective results. four different performance metrics used analyses pearson linear correlation coefficient root mean square error measure accuracy objective metric predicting values. spearman correlation coefficient evaluates monotonicity mapping objective metric results outlier ratio measure consistency objective metrics prediction values. performance objective metrics calculated stereo video database using mentioned performance metrics compared metrics stereo saliency maps taken account. table table show performance metrics original metrics stereo saliency information incorporated. observed tables saliency prediction general improves performance objective metrics. case metrics improvements average less case. fact information reference video available quality assessment thus accurate assessment possible. worth noting metrics evaluated study incorporate saliency maps original design. metrics q_farias q_sadaka vqsm nospdm q_ryu receive less improvement modified stereo saliency information. psnr receives improvement integrated saliency. highest amount improvement compared metrics. note expected psrn receives improvement perform smart comparisons subtract pixel values. addition incorporating stereo saliency information generated using lvbsd quality assessment tasks examine added value saliency information resulted several state-of-the-art vams namely vams fang coria park following considered common practice saliency prediction studies also evaluations results itti fig. shows improvements quality assessment achieved using various vams. observed fig. lbvsd resulted highest improvements quality assessment. moreover metrics already saliency information receive less improvement compared metrics. fig. resulting improvements saliency maps different vams integrated quality metrics. metrics left right psnr ssim ms-ssim phvsd phsd q_shao flosimd metrics left right iqvg gbim nrpbm q_blur_farias q_block_farias q_sadaka vqsm nospdm q_ryu fig. resulting improvements saliency maps lbvsd integrated quality metrics. metrics left right psnr ssim ms-ssim phvsd phsd q_shao flosimd metrics left right iqvg gbim nrpbm q_blur_farias q_block_farias q_sadaka vqsm nospdm q_ryu metrics vams park itti shown result less improvements. might fact less accurate presence distortions general lower saliency prediction performance video repeating patterns curves different vams fig. suggests different vams show kind agreement providing additional performance improvements integrated different quality metrics. improvement amplitude however varies another. case metrics gbim nrpbm received highest improvements. study performance improvements using stereo saliency information type distortion separately. table table table contain values metrics incorporation stereo saliency maps. fig. shows improvements case quality assessment different kinds distortions. observed table table table fig. different kinds distortions receive roughly similar amount improvements except awgn case could less accurate disparity estimation distorted videos type distortion. observations table fig. metrics show higher degree consistency improvements receive saliency information different kinds distortions metrics. words regardless distortion type metrics seem show similar amount improvement pcc. addition observations regarding saliency integration improvements deduct table q_shao deliver superior video quality assessment performance comparison metrics. case metrics q_ryu nospdm demonstrate superior quality assessment performance. moreover regarding strengths weaknesses individual metrics following facts drawn table table psnr particularly measuring blur whereas metrics really good particular distortion. metrics perform well video compression quality measurement. except psnr ssim metrics show fair performance depth compression artifacts. interestingly metrics better performance quality assessment ones. fact metrics generally designed specific target application mind generally successful paper study added value using stereo saliency prediction full-reference no-reference quality assessment tasks. leverage stereo saliency prediction results modify quality metrics re-evaluate performance. measure performance improvements using large database stereoscopic videos several representative types distortions. performance evaluations revealed using stereo saliency general improves quality assessment accuracy. however improvements significant case video quality assessment. future works include investigating possibility integrating emotional features overall video quality experience. known images/videos affect people emotional level since emotions arise viewer image highly impact viewerâ€™s quality experience necessary investigate quality metrics integrated emotion detection features case video different case. ninassi task impact visual attention subjective image quality assessment eusipco heynderickx visual attention objective image quality assessment based eye-tracking data ieee transactions circuits zhang learning blind image quality index based visual saliency guided sampling gabor filtering icip w.y.l. akamine m.c.q. farias studying added value visual attention objective image quality metrics sibgrapi conference sadaka no-reference perceptual image sharpness metric based saliency-weighted foveal pooling icip zhang no-reference image quality metric based visual quality saliency springer journal communications computer harel koch perona graph-based visual saliency nips saliency structure stereoscopic image quality assessment method optik vol. jiang duan shao visual attention stereoscopic image quality assessment journal software vol. zhang saliency detection spectral residual approach ieee computer society conference computer vision pattern wang simoncelli a.c. bovik multiscale structural similarity image quality assessment asimolar conference sheikh bovic image information visual quality ieee transactions image processing vol. feb. hasan j.f. arnold m.r. frater no-reference quality assessment videos based human visual perception h.r. yuen generalized block-edge impairment metric video coding ieee signal processing letters vol. f.c. roffet blur effect perception estimation no-reference perceptual blur metric spie electronic imaging symposium gabarda cristobal blind image quality assessment anisotropy journal optical society america vol. dec. iso/iec jtc/sc/wg common test conditions hevcavc-based doc. switzerland november video database digital multimedia university british columbia available http//dml.ece.ubc.ca/data/hvd/ recommendation subjective video quality assessment methods multimedia applications coria nasiopoulos guidelines improved quality experience mobile displays journal society recommendation itu-r bt.- methodology subjective assessment quality television pictures coria nasiopoulos automatic stereoscopic video reframing\" proc. dtv-conference true vision capture hevc fraunhofer https//hevc.hhi.fraunhofer.de/ view synthesis reference software wg.sc.org march machajdik hanbury affective image classification using features inspired psychology theory proceedings banitalebi-dehkordi video quality assessment thesis university british columbia matsuyama nobuhara takai tung video applications springer publishing isbn banitalebi-dehkordi m.t. pourazad panos nasiopoulos video quality metric video compression ieee ivmsp workshop appina manasa channappayya full-reference stereoscopic video quality assessment metric icassp march usa. jakhetiya qiao thalmann model-based reference-less quality metric synthesized images using local image", "year": "2018"}