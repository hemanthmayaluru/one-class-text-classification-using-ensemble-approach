{"title": "Detection, Recognition and Tracking of Moving Objects from Real-time  Video via Visual Vocabulary Model and Species Inspired PSO", "tag": ["cs.CV", "cs.AI"], "abstract": "In this paper, we address the basic problem of recognizing moving objects in video images using Visual Vocabulary model and Bag of Words and track our object of interest in the subsequent video frames using species inspired PSO. Initially, the shadow free images are obtained by background modelling followed by foreground modeling to extract the blobs of our object of interest. Subsequently, we train a cubic SVM with human body datasets in accordance with our domain of interest for recognition and tracking. During training, using the principle of Bag of Words we extract necessary features of certain domains and objects for classification. Subsequently, matching these feature sets with those of the extracted object blobs that are obtained by subtracting the shadow free background from the foreground, we detect successfully our object of interest from the test domain. The performance of the classification by cubic SVM is satisfactorily represented by confusion matrix and ROC curve reflecting the accuracy of each module. After classification, our object of interest is tracked in the test domain using species inspired PSO. By combining the adaptive learning tools with the efficient classification of description, we achieve optimum accuracy in recognition of the moving objects. We evaluate our algorithm benchmark datasets: iLIDS, VIVID, Walking2, Woman. Comparative analysis of our algorithm against the existing state-of-the-art trackers shows very satisfactory and competitive results.", "text": "abstractâ€” paper address basic problem recognizing moving objects images using visual vocabulary model words track object interest subsequent video frames using species inspired pso. initially shadow free images obtained background modelling followed foreground modeling extract blobs object interest. subsequently train cubic human body datasets accordance domain interest recognition tracking. training using principle words extract necessary features certain domains objects classification. subsequently matching feature sets extracted object blobs obtained subtracting shadow free background foreground detect successfully object interest test domain. performance classification cubic satisfactorily represented confusion matrix curve reflecting accuracy module. classification object interest tracked test domain using species inspired pso. combining adaptive learning tools efficient classification description achieve optimum accuracy recognition moving objects. evaluate algorithm benchmark datasets ilids vivid walking woman. comparative analysis algorithm existing state-of-the-art trackers shows satisfactory competitive results. ffective recognition objects tracking real-time video stream processing data involve integration background modelling shadow removal foreground modelling proper detection objects. recognition detected objects done extracting features obtained principle words extracted feature sets tracked successive test frames species inspired pso. although various detection tracking algorithms exist still; object detection recognition effective tracking feature sets adoptability handling occlusions noise still standing challenge field computer vision. order perform well domain interest tracking algorithm satisfactory training model utmost importance. recent years several attentions given direction achieve share goal paper. generally appearance based tracking algorithms types mainly; generative discriminative several tracking algorithms based static appearance models exists either trained using first consecutive iterations defined manually algorithmic frameworks often fail deal momentous appearance changes cause nonlinear transformation appearance given object. challenges lead difficulty absence sufficient amount priori knowledge. paper considered several appearances given training object interest capture momentous nonlinear changes appearances explained length section here visual vocabulary model using words extract necessary features certain instances objects rigorous high level training. subsequently apply features test datasets recognize locate objects video scenes. using visual instance occurrence probabilistic presence imply certain domain obtain optimum accuracy domain recognition well. organization paper constitutes review related works field object detection recognition especially based supervised learning briefly described following section section explains proposed method detection recognition tracking specifically section describes concept visual vocabulary model object recognition. experimental results several datasets comparative analysis state-of-theart algorithms presented section section concludes paper discusses future possibilities improvements. numerous color histograms based tracking algorithms proposed recent years. mean shift tracking algorithm extended collins scale variation object interests video frame. perez used color histogram addition particle filter tracking objects video frames. spatiogram based approach proposed capture spatial relationships statistical properties pixel birchfield rangarajan developed locality sensitive histogram pixel finer distribution visual feature points object tracking video scenes. histograms oriented gradients proposed object tracking addition integral histogram covariance region descriptors based approaches introduced tracking combine different features. local binary patterns well haar-like features proposed appearance based tracking objects spatio-temporal representation combined genetic algorithm also used feature extraction recently pixel based segmentations applied handle tracking. various generative models proposed multiple object tracking past years. sparse generative appearance modeling implemented build appearance model objects. gaussian mixture models popular generative approach tracking. apart several mixture models used tracking earlier days finite mixture models priebe introduced algorithm based recursive mixture density estimation. extract time-invariant characteristics authors present bayesian tracking approach using autoregressive hidden markov model robust visual tracking. recent years discriminative models leading field object tracking method binary classifier trained input video sequence separation target background. classifiers extensively used object tracking ranking semi-boosting support vector machine boosting structured output online multiinstance boosting trained classifier integrated tracking tackle appearance based changes varying illumination. accurate detection objects interest across multiple frames tracking recognized objects still challenge. order that first model background remove hard shadows background extract exact area occupied object frame. next model foreground subtract background model without shadow obtain blob object. recognizing object inside blob train machine learning inspired visual vocabulary model objects represent domain interest recognition tracking. cases i.e. case training stage extract features objects training data principle words testing phase technique extract features objects test data. classification extracted feature sets track features interest recognized objects successive video frames species inspired pso. background modelling integral part algorithm. part consists pretreatment frame video sequence followed temporal image analysis. update background continuously adapt changing background variations. background adaptive threshold order differentiate foreground background objects. finally apply certain domain centric morphological operators updated background obtain smooth background images. obtained subtracting time step image obtained subtracting successive video frames current video frame background model. deal sudden illumination variation and-or operation performed pixel image gray histogram pixel background pixels foreground pixels denoted respectively. probability background pixel misidentified foreground pixel vice versa follows ğ‘ƒğ¹|ğµ probability background pixel probability foreground pixel. pf|b significant morphological operation post-process pb|f smaller. priori probability background calculated gray histogram image following noise variance model expressed fitting criterion describes threshold value defined ğ‘’ğ‘€ğ‘–ğ‘› apart moving objects binary images contain residual noise. object detection fails fatally many pixel holes image. morphological operators help remove holes present many noise smoothening edges blob. morphological operators used experiment adaptive kernel operator gaussian operator laplacian filter. extracted frame compared previous frame predicting similarity order obtain consecutive pixel values frames expressed using radiometric similarity particular window specific video frame pixel centers compared succeeding images temporal binary image moving object radiometric similarity value formally expressed application gaussian smooth filter suppresses high frequency textures invariant original images. smoothed color images converted gray scale following color model definition detect edges formally ğ¸ğ‘œğ‘Ÿğ‘– â€–ğ‘’ğ‘‘ğ‘”ğ‘’â€– ğ¸ğ‘–ğ‘›ğ‘£ â€–ğ‘’ğ‘‘ğ‘”ğ‘’)â€– ğ¸ğ‘œğ‘Ÿğ‘– edge original image applying smooth filter ğ¼ğ‘œğ‘Ÿğ‘– original image. ğ¸ğ‘–ğ‘›ğ‘£ edge color invariant image applying smooth filter ğ¼ğ‘–ğ‘›ğ‘£is color invariant image. here values hard shadow edge mask constructed choosing strong edges original images absent invariant images. thus visual vocabulary model machine learning based image images classification model documents labelling specific features words. observing presence feature words image visual vocabulary model predict domain image arrangement image recognize different objects. adopted method yields satisfactory results limited training samples accuracy increases increase training datasets. paper scene recognition essential narrow objects present scene. recognition using visual vocabulary consists selection distinct words normalization surrounding regional content. assigning descriptor normalized content helps matching captured objects domain interest. localize keywords first step extract features object interest distinct invariant different scale illumination based conditions even presence noise. construct visual vocabulary corpus training images need stored feature space order model descriptor modelled descriptors clustered quantization feature space distinctive visual words visual words signify center cluster. given video frames closest matching visual points recognized corresponding features. words feature sets used define principle description given videoframe. process divided three steps namely; tokenization phase similar feature patches labelled kmean clustering. counting phrase number tokens counted estimate scene. finally different tokens assigned different weightage based arrangement differentiates various objects. thresholds manually assessed hard shadow edge mask maps selected shadow edges strong edges subsequent hard shadows images. selects edges belonging shadows. consider poisson equation solution reinforce shadow portions derivative frames. begin with shadow edge masks kinds merged mask represents vague shadow represents hard shadow. furthermore masking applied gradient field ğ‘šğ‘ğ‘ ğ‘˜ gradient field along axis. clipped derivatives denoted calculation scalar represented shadow image shadow free image respectively reconstruction. figure shows actual video frames; column modelled background column foreground modelling. figures visible accepted foreground objects. ğ‘‡ğ‘—ğ‘–) ğ‘‡ğ‘—ğ‘–) mahalanobis distance transformed locations diagonal covariance. root node optimum location stated ğ·ğ‘šğ‘–) ğ·ğ‘šğ‘–) represents root nodeâ€™s response distance-transformed version child node. visual word tokenization explained furthermore visual word occurrence frequency explained following section. signifies number time particular word vector represents class object varied frames. evidently parameter decides characteristics particular object. validate classification cross validation approach applied randomly splitting array objects train data subsets test data subsets. creates confusion matrix comparing correct incorrect classification features training visual vocabulary model. along principle diagonal confusion matrix represents number correctly classified objects. ratio correctly classified object total number objects identified gives validation accuracy. paper essentially considered discriminative model tracking objects different appearance improvement validation score approximating similarity measures modelling extracted features classified order distinguish objects interest objects present videoframe. used nonlinear support vector machine feature classifier. cubic bundles consider consecutive triples words classification. case cubic performed better types well classifiers. polynomial kernel cubic input vector features calculated training samples. free parameter indicating equation homogeneity. section followed similar approach words extract textual distribution feature test objects video scenes. classification process similar feature different objects lead uncertainty feature assignment. dealing uncertainty implicit shape model proposed algorithm extraction local features matching visual vocabulary done using soft matching. time validation classification process used notion soft computing basically heuristic interpretation matching threshold. following equation expresses contribution feature location position object class matching visual keywords indicating potentiality belonging class thus indicates probability feature frame location belong class image position weights populated continuous weighing region object position visual keyword first term right-hand side indicates stored occurrence distribution weighted second term probability feature belonging exact class kernel bandwidth denoted volume denoted varied radius kernel. order hypothesized interest object size scale coordinate parallelly updated. strategy makes easier deal partial occlusions also typically requires fewer training examples. different object obscure another overlap corresponding support regions. circumstances competition objects elevates subjugate overlapping part order effectively design competition phenomenon visual problem needs merged competition process. evaluate fitness value overlapping part competition ability overlapping part viewed whole projected onto learned subspace corresponding object. define power object species following manner ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘˜ overlapping part object corresponding subspace respectively. similar interactive likelihood object overlapping regions calculated mutual likelihood species describes competition ability. higher competition ability species like competition. means species competition likely object occluding object species involved. annealed gaussian based algorithm considered paper conventional requires careful fine tuning various parameters. algorithm particles corresponding velocities updated mentioned manner ğ‘£ğ‘–ğ‘›+ linear time matching function represented pyramid match kernel model bridge feature sets variable cardinalities. input histogram pyramid ğ»ğ¿âˆ’] number pyramid levels expressed histogram vector point defined species inspired framework provides effective track multiple object detected recognized aforementioned method first singular object tracking following analogies need assumed multiple object tracking postulates easily extended creating tracker object. trackers managed independently. case occlusion support regions concerning objects overlap implies intersectional area species elementary both. subsequently repulsion competition among species arise aspire resource stronger higher probability winning competition. course video scene overlap object areas occlusion related features become ambiguous. handle hindrance design multiple-species-based algorithm. principle idea behind approach divide groundtruth particles object various species according species object numbers successfully model relations partial visibility among varied species. detailed description species inspired algorithm briefly described following sections. evaluate proposed algorithm benchmark sequences namely ilids vivid walking woman following section discuss various attributes aforementioned datasets. primary challenges ilids dataset scale variation plane rotation occlusion resolution illumination variation video consists total number four people walking across camera view camera mounted isometric angle carries trolley. video minutes long frames second frame dimension pixels scaled resolution analysis. woman dataset much challenging handle illumination variation scale variation occlusion deformation motion blur fast motion plane rotation video frames resolution. camera view follows woman walking past several cars. vivid dataset part darpa vivid program consisting video sequences. deal nine videos namely redteam. video contains challenges scale variation occlusion plane rotation plane rotation resolution. aerial footage driving straight road turning corner forming long shadow cast object. therefore shadow removal gives better result tracking. walking dataset contains difficulties like scale variation occlusion resolution. video contains frames dimension pixels. video people walking corridor office interior. video many ways similar ilids dataset. following section demonstrate accuracy algorithm susceptibility handling challenges offered benchmark datasets. process frame original color channels reconstruct image feeding normalized color channel values. normalized image removes shadow component image essentially helps accurate tracking. step convert image binary image background subtraction dilate image employing morphological operations. however image preserve edges satisfactorily enough. thus extract binary image edges intact simple background subtraction pointwise multiply images image edges preserved. ğ‘¥ğ‘–ğ‘›+ğ‘– ğ‘£ğ‘–ğ‘›+ absolute values samples gaussian probability distribution zeromean gaussian disturbance stops algorithm getting trapped local optima. help adaptive simulated annealing covariance matrix changed ğ‘’âˆ’ğ‘ğ‘›. here transition distribution predefined covariance matrix annealing constant iteration number components decrease proportion iteration number results fast rate convergence. occlude time repulsion force added evolution process particles subsequently iteration step becomes follows parameter gaussian random number sampling third term right-hand side equation depicts shared effect object words competition phenomenon observation level modelled paper. also competition model state space modelled drive evolution process species right direction. tracking algorithms appearance models updated occlusion. however appearance object occlusion change cause tracker fail recapture object appearance occluded anymore. selective updating algorithm implemented cope appearance changes occlusion pixels belonging visual part objects cumulatively updated normal pixels part overlapping region projected onto subsequent subspace object. errors reconstruction calculated. error smaller predefined threshold pixels inside overlapping area updated subsequent subspace. proposed method evaluated benchmark datasets compared existing state-of-the tracking algorithms. brief description experimental datasets shown followed experimental parameter settings analysis. test algorithm dataset mentioned aforementioned setting. confusion matrix shows reached accuracy. here consider inria person dataset training visual vocabulary model various angle postures accurate detection recognition portrayed fig. training always leads higher accuracy. training data consisted partial photos train almost similar dimension like cars. classifier maximum confusion situation reflected confusion matrix. training consider domain train data sets visual vocabulary features. weâ€™re extracting points calculating probable occurrences subsequent frames continuing process extract points certain domain oriented objects different angle-posture-view high definition picture datasets better accuracy. visual vocabulary using cubic based classification covers parameters namely domain detection scene object identification video frames independent camera axis orientation camera background relationship surroundings. provides recognition accuracy roughly extracted trained features species inspired accurate content aware tracking. following process unattended luggage also recognized. luggage rigid object remains stationary video moved human forms connected blob human. normally cases cannot track successfully feature driven input species inspired results shown below. next comparative analysis frame second provided demonstrated table implement algorithm vivid dataset compare various state-of-the-art methods obtain necessary data table plots like curve scatter point data show classifier performance plot true positive rate false positive rate. prediction model curve shows structure containing classification object function prediction. structure allows make predictions data models include principal component analysis applying extracted features test datasets using visual points prediction objects interest video sequence done. subsequently using trained model reference recognize newly arrived objects shown validation accuracy roughly train models using machine learning learners applied video sequences algorithm predicts recognition objects interests present consequent video frames stated above. cases algorithm performs competitively better popular existing approaches. fact algorithms effective deal certain challenges offered datasets susceptible enough cope challenges datasets stated earlier section table represent comparative performance different trackers proposed algorithm. table entry numerator term represents tracking score denominator term represents false positive tracking. careful inspection table. reveals fact cases algorithm performs better existing ones. fig. graphically depicts stated fact performance measure indicates proposed algorithmâ€™s flexibility adapting real-life challenges. seen algorithm performs best walking datasets expected fewer number challenging attributes. performs well ilids vivid datasets despite low-resolution video frames. learning spatio-temporal representations action recognition genetic programming approach ieee trans. cybernetics vol. nov. xiao track segment iterative unsupervised approach video object proposals larese granitto finding local leaf vein patterns legume characterization classification machine vision applications foggia greco saggese vento method detecting long term left baggage based heat visapp yang object tracking benchmark ieee trans. pattern analysis machine intelligence vol. sept. wang visual tracking probability continuous outlier model proc. ieee conf. comput. vis. pattern recognit. yang wang m.-h. yang visual tracking locality sensitive histograms proc. ieee conf. comput. vis. pattern recognit. wang m.-h. yang least soft-thresold squares tracking proc. ieee conf. comput. vis. pattern recognit. zhang zhang m.-h. yang real-time compressive tracking proc. eur. conf. comput. vis. tang robust tracking weakly supervised ranking proc. ieee conf. comput. vis. pattern recognit. m.-h. yang visual tracking adaptive structural local sparse appearance model proc. ieee conf. comput. vis. pattern recognit. sevilla-lara learned-miller distribution fields tracking proc. ieee conf. comput. vis. pattern recognit. ling real time robust tracker using accelerated proximal gradient approach proc. paper presents object detection recognition detected objects based visual vocabulary model tracking recognized objects using species inspired pso. train different objects separately several images multiple aspects camera viewpoints find best word points recognition. subsequently verify extracted features train images. word points applied regions based visual feature point analysis. comparative analysis done using visual word points. present similarity measures using approach feature matching. object satisfactorily detected. detection object recognition specific object interest done section finally features recognized objects tracked species inspired also efficiently handle tracking partial occlusions shown performance measure proposed algorithm done respect available benchmark data obtain satisfactory competitive results. future plan modify detection recognition scheme based theory intelligence. ieee conf. comput. vis. pattern recognit. oron bar-hillel levi avidan locally orderless tracking proc. ieee conf. comput. vis. pattern recognit. zhang ghanem ahuja robust visual tracking multi-task sparse learning proc. ieee conf. comput. vis. pattern recognit. shen ling online robust image alignment iterative convex optimization proc. ieee conf. comput. vis. pattern recognit. babenko m.-h. yang belongie robust object tracking online multiple instance learning ieee trans. pattern anal. mach. intell. vol. aug. shen real-time visual tracking using compressive sensing. cvpr hare saffari torr struck structured output tracking kernels proc. ieee int. conf. comput. vis. ling robust visual tracking vehicle classification sparse representation. pami dinh medioni context tracker exploring unconstrained environments proc. ieee conf. comput. vis. pattern recognit. huang yang kulikowsk robust tracking using local sparse appearance model k-selection proc. ieee conf. comput. vis. pattern recognit. kalal matas mikolajczyk learning bootstrapping binary classifiers structural constraints proc. ieee conf. comput. vis. pattern recognit. ling robust visual tracking using minimization proc. ieee int. conf. comput. vis. stalder grabner gool beyond semisupervised tracking tracking simple detection simpler recognition proc. ieee int. conf. comput. vis. workshop dollaÂ´r babenko belongie perona multiple component learning object detection proc. european conf. computer vision felzenszwalb mcallester ramanan discriminatively trained multiscale deformable part model proc. ieee conf. computer vision pattern recognition grabner leistner bischof semi-supervised on-line boosting robust tracking. forsyth torr zisserman eccv part lncs vol. springer heidelberg wang real-time moving object detection international symposium information technology application ross r.-s. m.-h. yang incremental learning robust visual tracking int. comput. vis. vol. avidan ensemble tracking ieee trans. pattern anal. mach. intell. vol. feb. tang brennan zhao co-tracking using semisupervised support vector machines proc. ieee conf. comput. vis. pattern recognit. adam rivlin shimshoni robust fragmentsbased tracking using integral histogram proc. ieee conf. computer vision pattern recognition vol. lepetit keypoint recognition using randomized trees ieee trans. pattern analysis machine intelligence vol. sept. nister stewenius scalable recognition vocabulary tree department computer science university kentucky grabner grabner bischof real-time tracking on-line boosting proc. british mach. vis. conf. tuzel porikli meer region covariance fast descriptor detection classification proc. eur. conf. comput. vis. adam rivlin shimshoni robust fragmentsbased tracking using integral histogram proc. ieee conf. comput. vis. pattern recognit. jiang \"shadow removal single image\" proc. ieee int'l conf. intelligent systems design applications dalal triggs histograms oriented gradients human detection proc. ieee conf. comput. vis. pattern recognit. collins leordeanu online selection discriminative tracking features ieee trans. pattern anal. mach. intell. vol. oct. porikli integral histogram fast extract histograms cartesian spaces proc. ieee conf. comput. vis. pattern recognit. birchfield rangarajan spatiograms versus histograms region-based tracking proc. ieee conf. comput. vis. pattern recognit. collins zhou open source tracking testbed evaluation site proc. ieee int. workshop perform. eval. tracking surveillance viola jones robust real-time face detection int. comput. vis. vol. avidan support vector tracking ieee trans. pattern anal. mach. intell. vol. aug. fisher pets surveillance ground-truth data sets proc. ieee int. workshop perform. eval. tracking surveillance jepson fleet maraghi robust online appearance models visual tracking. pami comaniciu ramesh meer kernel-based object tracking ieee trans. pattern anal. mach. intell. vol. collins mean-shift blob tracking scale space proc. ieee conf. comput. vis. pattern recognit. ojala pietikÃ¤inen mÃ¤enpÃ¤Ã¤ multiresolution grayscale rotation invariant texture classification local binary patterns ieee trans. pattern anal. mach. intell. vol. jul. p_erez vermaak gangnet colorbased probabilistic tracking proc. eur. conf. comput. vis. isard maccormick bramble bayesian multiple-blob tracker proc. ieee intâ€™l conf. computer vision vol. isard blake condensation-conditional density propagation visual tracking int. comput. vis. vol. riahi g.-a. bilodeau multiple object tracking based sparse generative appearance modeling image processing ieee international conference ieee chenglong haibin ling real time robust tracker using accelerated proximal gradient approach cvpr. ieee stauffer w.e.l. grimson \"adaptive background mixture models real-time tracking\" proc. computer vision pattern recognition -june mckenna raja gong \"tracking colour objects using adaptive mixture models\" image vision computing vol. bishop neural networks pattern recognition oxford university press york b.s. everitt d.j. hand finite mixture distributions chapman hall york g.j. mclachlan k.e. basford mixture models inference applications clustering marcel dekker inc. york c.e. priebe adaptive mixtures journal american statistics association c.e.priebed.j. maxchette adaptive mixtures recursive nonparametric pattern recognition pattern recognition c.e. priebe d.j. marchette adaptive mixture density estimation pattern recognition park kwon robust visual tracking using autoregressive hidden markov model cvpr ieee", "year": 2017}