{"title": "A Generalized Method for Integrating Rule-based Knowledge into Inductive  Methods Through Virtual Sample Creation", "tag": ["cs.LG", "cs.AI", "cs.CV"], "abstract": "Hybrid learning methods use theoretical knowledge of a domain and a set of classified examples to develop a method for classification. Methods that use domain knowledge have been shown to perform better than inductive learners. However, there is no general method to include domain knowledge into all inductive learning algorithms as all hybrid methods are highly specialized for a particular algorithm. We present an algorithm that will take domain knowledge in the form of propositional rules, generate artificial examples from the rules and also remove instances likely to be flawed. This enriched dataset then can be used by any learning algorithm. Experimental results of different scenarios are shown that demonstrate this method to be more effective than simple inductive learning.", "text": "hybrid learning methods theoretical knowledge domain classified examples develop method classification. methods domain knowledge shown perform better inductive learners. however general method include domain knowledge inductive learning algorithms hybrid methods highly specialized particular algorithm. present algorithm take domain knowledge form propositional rules generate artificial examples rules also remove instances likely flawed. enriched dataset used learning algorithm. experimental results different scenarios shown demonstrate method effective simple inductive learning. majority machine learning algorithms learn scratch training models examples without considering existing domain knowledge. unlike human learners systems capable accumulating domain knowledge sequentially improving ability learn tasks. algorithms require significant amount training data training time perform well domain knowledge learning shown boost learning speed accuracy significantly fact hybrid systems information misinformation source. necessary real world learning problems complex enough considerable amount training data required; training data quite expensive acquire also prone noise. lack data compensated domain knowledge equally expensive imperfect. thus balanced system uses always performs better. propositional rules kbann focl certainty factors rapture invariance hints ting yuâ€™s dissertation provides systematic overview hybrid machine learning algorithms. identified four categories methods providing knowledge hybrid methods. methods also follow steps taken typical inductive learning algorithms. using prior knowledge preprocess training data; using prior knowledge initiate hypothesis; using prior knowledge alter search objective; using prior knowledge augment search operation. first method; using prior knowledge preprocess training data dependent underlying machine learning algorithm. method tailors training data cleaning selecting augmenting. scarcity training data noise training data major concern inductive algorithms. domain knowledge preprocessors remove flawed training examples well virtual training examples. popular machine learning algorithms dependent training dataset alone. virtual training examples offer general purpose including domain knowledge used inductive algorithm. method adding virtual examples gained popularity recent years. niyogi used virtual examples invariance neural networks schÃ¶lkopf decoste sassano researched virtual examples introduce invariance support vector machines. however methods used predominantly introduce invariance. invariance knowledge certain transformations sample equivalent other. thus invariant learners unaffected perturbation data. propositional rules production rules. human experts express knowledge terms rules easily. therefore methods take domain knowledge form rules would great improvement. example ruleset above literals implicated literals refers actual class. therefore hierarchy rules made successive layer literals made literals. however algorithm cannot work rules form. must first draw distinction kinds literals appear rule set. literal atomic made literals. thus input features dataset atomic. literal made literals called non-atomic. goal preprocessing step conversion rules operational form. operational rule class variable post-condition made conjunction atomic literals. hence logical cannot appear operational rules. non-operational rules converted operational form. definition rule rule called operational antecedents conjunction atomic literals consequent class attribute. preprocessing step takes operational rules converts operational form. done backward chaining fashion. mode operation algorithm summarized below algorithm first selects rules whose head matches target class attribute. preconditions selected rule form logically sufficient condition target concept. algorithm takes non-atomic literal finds associated rule particular literal post-condition. non-atomic literal substituted pre-conditions. substituted literals also contain non-atomic literals substituted pre-conditions. process \"unfolding\" domain theory continues sufficient conditions restated terms atomic literals. example sample ruleset unfolded research introduces method called rascal uses propositional rules preprocess datasets. method adds virtual examples conform provided rule set. hybrid method consider either rule training dataset error-free. rules rule judged scoring criterion includes accuracy range generality. training samples also judged conformance rules samples considered flawed pruned dataset. source compensate otherâ€™s deficiencies. resultant dataset incorporates domain knowledge. refined dataset used algorithm. universality makes rascal highly robust. paper explain rascal analyze performance applied real world problems. real world domain molecular biology specifically problem recognizing eukaryotic splice junctions promoter genes used experiments. shown rascal refined datasets perform much better original dataset even less data provided. goal rascal dataset conforms rules. motivation behind straightforward. rules embody domain knowledge must surely validity. virtual examples conform rules generated simply samples follow conditions class value rules. however simply following would degrade performance rule misleading. rascal follows method check balance. rascal algorithm works three steps. first provided rule preprocessed normalized conform specification required algorithm. normalized rules evaluated data score calculated. finally virtual training samples generated based score examples likely error-prone also removed. however function measures utility rule terms influence compliance training dataset. want generate training instances good generalization goal instead conformance dataset. rules highly specific training skewed also measure generalization capability rule. useful observation rule operational rule precondition simply conjunction feature values. therefore literals precondition total number features dataset. since rule conjunction literals rule becomes specific literals added rule features possible match. consider features rascal takes constants input along ruleset dataset. values would greatly affect performance denote many changes take place dataset. denotes number virtual samples generated rules expressed percentage training data set. value significantly influence performance preprocessed dataset. many virtual examples hamper performance less virtual examples would yield noticeable performance gain. threshold pruning example; thus setting higher value result less pruning. explained generating operational rule algorithm would calculate score would determine utility rule. utility score would used virtual example generation existing dataset pruning. consider training rule imperfect scoring criterion cannot faith source. thus scoring function balanced. obvious evidence utility accuracy correctness; ratio number examples correctly classified rule number examples actually matches precondition rule. avoid possibility division zero divisor. number examples successfully classified. number examples matched however correctness ratio even rules match instances high correctness. instance rule matches example also correctly classifies rule matches examples correct cases however second rule clearly useful first. thus correctness alone sufficient criterion utility. instead utility composed correctness scope extent rule. scope rule defines ratio combining provides balance criteria. rule high correctness scope less useful rule high scope reasonable correctness. hand donâ€™t want give utility rules high scope perform sample valid sample spawned rule. features present rule arbitrarily concern rule. however would prefer virtual examples distributed randomly possible; would increase probability good generalization. virtual sample generation rascal works generating initial template examples generated rule preconditions rule become value features. finally attributes missing rule randomly. class label taken rule. creates valid example. sample generation rule taken earlier generated operational ruleset shown below ğ¶ğ¶ğ¶ğ¶ğ‘ğ‘ğ¶ğ¶ğ¶ğ¶ ğ‘ğ‘=tb=??ğ‘¥ğ‘¥=ğ‘‡ğ‘‡ğ‘¦ğ‘¦=ğ¹ğ¹ğ‘§ğ‘§=??ğ¶ğ¶ğ¶ğ¶ğ‘ğ‘ğ¶ğ¶ğ¶ğ¶=ğ‘‡ğ‘‡ ğ‘ğ‘=tğ›ğ›=ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘=ğ“ğ“ ğ‘¥ğ‘¥=ğ‘‡ğ‘‡ğ‘¦ğ‘¦=ğ¹ğ¹ğ’›ğ’›=ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹=ğ‘­ğ‘­ ğ¶ğ¶ğ¶ğ¶ğ‘ğ‘ğ¶ğ¶ğ¶ğ¶=ğ‘‡ğ‘‡ ğ‘ğ‘=tğ›ğ›=ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘=ğ…ğ…ğ‘¥ğ‘¥=ğ‘‡ğ‘‡ğ‘¦ğ‘¦=ğ¹ğ¹ğ’›ğ’›=ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹ğ‘¹=ğ‘­ğ‘­ ğ¶ğ¶ğ¶ğ¶ğ‘ğ‘ğ¶ğ¶ğ¶ğ¶=ğ‘‡ğ‘‡ virtual samples generated rule. algorithm needs calculate number virtual samples generated rule method described generate instances. score generated earlier step used calculate want higher scoring generate instances however scoring rules totally left either. normalize scores rule total score rules. prune sample sufficient confidence giving right classification. rules accuracy based dataset. sample also accuracy based ruleset. sample deemed incorrect rule high sample utility score probable misclassified. hand high scoring rule agrees sample confidence sample correct. thus much confidence sample calculated voting system. calculate total utility score sample sample. section reports experimental results using rascal augment datasets. real world problems experimented. compared performance several popular classic learning algorithms standard feedforward neural network k-nearest neighbour support vector machines also compared rascal neural network based theory refine system kbann first dataset promoter recognition dataset. promoter short sequence precedes gene sequence distinguished nonpromoter. input sequence nucleotides dataset instances positive negative examples. associated ruleset rules operational rules generated. second dataset splice-junction determination. class problem; task determine three categories specified sequence belongs exon/intron borders intron/exon borders imbued ruleset. conclusion performance virtual samples depend strength domain knowledge. strong domain knowledge would speed learning process large extent. advantage rascal clearly evident learning curves figure test conducted full dataset. training examples selected randomly rest became test set. error rates averaged algorithms. rascal augmented datasets clearly require less data. another useful insight fact that data given rascal augmented datasets still perform good level. using algorithms original data suffers poor initial performance. data provided performance original data catches important decision made learning much virtual samples generated. generating fewer samples beneficial; many virtual samples inevitably lead over-fitting. conducted neither. input also sequence nucleotides. dataset instances selected randomly population percentage split classes neither examples. associated ruleset rules operational rules generated. conducted several tests datasets. first test used full dataset refinement virtual examples added therefore chosen. refined dataset original dataset performance compared. also show algorithms fared given original dataset. first test conducted using fold cross validation second test data used remaining test set. thus second test much difficult first. final test performance algorithms trained virtual samples. curious test shows knowledge virtual samples contain. accuracy rates report simple averages trials. results presented table apparent results rascal augmented datasets outperform original datasets. finding statistically significant. unexpectedly even improves performance kbann datasets also uses ruleset domain knowledge. performance gain even pronounced test dataset. algorithms show significant performance gains. performance dataset shows rascal speeds learning process requiring smaller amount data also statistically significant. interesting result comes learning virtual samples also shows degree good performance. knowledge pazzani brunk silverstein knowledge-intensive approach learning relational concepts. proceedings eighth international workshop machine learning. francisco increasing virtual samples boost performance. however increasing size around performance declines error curves takes upward trend. therefore virtual samples increase performance extent. utility gets diminished. conclusion made value must carefully chosen trial. learning process humans largely based augmenting knowledge previously acquired. viable substantially increase learning performance. current inductive algorithms extremely good learning training data. therefore method proposed provides generalized method applied increase performance inductive learning algorithm. refining datasets enables tried tested inductive algorithms also speedy accurate learning. experimental results also prove point. virtual examples field many research possibilities. algorithm currently supports propositional rules. extended learn association rules well. research could done enable powerful knowledge representation techniques first order logic description logics. even current propositional rule based method extended learn association rules well. virtual sample generation used incorporate form knowledge well. currently framework exists hybrid learning algorithms. structured framework standing firm theoretical basis also goal hybrid learning research. possibilities almost endless.", "year": 2011}