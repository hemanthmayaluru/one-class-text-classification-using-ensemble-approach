{"title": "LADDER: A Human-Level Bidding Agent for Large-Scale Real-Time Online  Auctions", "tag": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "abstract": "We present LADDER, the first deep reinforcement learning agent that can successfully learn control policies for large-scale real-world problems directly from raw inputs composed of high-level semantic information. The agent is based on an asynchronous stochastic variant of DQN (Deep Q Network) named DASQN. The inputs of the agent are plain-text descriptions of states of a game of incomplete information, i.e. real-time large scale online auctions, and the rewards are auction profits of very large scale. We apply the agent to an essential portion of JD's online RTB (real-time bidding) advertising business and find that it easily beats the former state-of-the-art bidding policy that had been carefully engineered and calibrated by human experts: during JD.com's June 18th anniversary sale, the agent increased the company's ads revenue from the portion by more than 50%, while the advertisers' ROI (return on investment) also improved significantly.", "text": "promising field online advertising greatly promotes effectiveness industry typical environment consists exchanges supply side platforms data management platforms demand side platforms adxs dsps utilize algorithms buy/sell real-time. ssps integrate information publishers offer requests publishers adxs. puts offers dsps bidding. dsps target appropriate involved user based information supplied dmps return bids displays highest bidder charges winner general second price obviously process many dsps/adxs bidding offer auction game incomplete information. however online industry ignores fact considers solved problem existing dsps model auction games supervised learning problems predicting click rate conversion rate using effective cost mille bids present ladder first deep reinforcement learning agent successfully learn control policies largescale real-world problems directly inputs composed high-level semantic information. agent based asynchronous stochastic variant named dasqn. inputs agent plain-text descriptions states game incomplete information i.e. real-time large scale online auctions rewards auction profits large scale. apply agent essential portion jdâ€™s online advertising business find easily beats former state-of-the-art bidding policy carefully engineered calibrated human experts jd.comâ€™s june anniversary sale agent increased companyâ€™s revenue portion advertisersâ€™ also improved significantly. researchers made great progress recently learning control agents directly high-dimensional sensory inputs like vision domains atari games reinforcement learning agents human-level performance. however real-world problems high-level semantic information inputs rather sensory inputs human experts usually read understand inputs plain-text form judging expertise. realworld problems much challenging video games always larger solution space states partially observed. real-world problems tackled state-ofthe-art agents now. paper demonstrates agent named ladder problem. using deep asynchronous stochastic qnetwork agent improves performance jdâ€™s real-time bidding business. jd.com started business first employed industry state-of-the-art approach ecpm bidding calibrated model depicted figure soon found impossible calibration model stable performance practice critical business keep breaking even. result introduced method fine grained coefficients calibrated human experts. nutshell bidding mechanism humanmachine hybrid control system operators modified calibration coefficients tens times day. first solution space auction game tremendous. system bidding auctions second assume actions episode simple math shows solution space comparison solution space game second state-of-the-art algorithms inherently sequential hence cannot applied large-scale practical problems auction game online service cannot afford inefficiencies sequential algorithms. third auction requests actually triggered users randomness human behaviors implies stochastic transitions states. thatâ€™s different atari games text-based games game last least thereâ€™s much human-readable high level semantic information crucial bidding e.g. stock keeping units customer viewed bought recently long viewed bought them price advertised etc. although sophisticated feature engineering utilize information model like wide deep models factorization machines already place hybrid system taking account jdâ€™s scale models billions features therefore heavy react instantly rapidly varying auction environment leading poor performance. paper model auction game partially observable markov decision process present dasqn algorithm successfully solve inherently synchronousness algorithms stochastic transitions game. encode auction request plain text domain specific natural language feed encoded request deep convolutional neural networks make full high-level semantic information without sophisticated feature engineering. results lightweight model responsive expressive update real-time reacts changes auction environment rapidly. whole architecture named ladder. evaluated ladder significant portion business online test experimental results indicate industry solving problem ladder easily outperformed human expert calibrated ecpm policy jd.comâ€™s june anniversary sale agent raised companyâ€™s revenue portion advertisers also improved much provides ability agent learn interactions environment paper consider auction environment time step agent observes auction publisher participate auction. agent selects legal action acts while agent gets real number reward formularize sequential process whose dynamics defined joint probability distribution pr{ğ‘‹ model auction game pomdp rather standard real-world problem little state observed game assumed terminate restart cycle. state space pomdp huge still finite standard methods q-learning policy gradient applied learn agent interaction q-learning variants especially learns value function indicates future rewards since current state derives policy ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ğ‘„ loss function step defined algorithms sequential step unacceptable application scenario. presented n-step q-learning among asynchronous algorithms decoupled algorithms extent agents could steps training steps well could learn several copies game time. however n-step q-learning still cannot solve auction game scale requires full decoupling rather semi decoupling. applied cnns monte carlo tree search game agent namely alphago beat human experts open competition. argue auction game much larger solution space makes tree search methods thoroughly impractical. furthermore perfect information auction games incomplete information form human readable high-level semantic info. recurrent neural networks especially lstms extensively used tasks. text-based game researched used lstms instead dqn. however game studied tiny state space compared auction games. addition rnns need sophisticated feature engineering understand high-level semantic information makes model large react instantly. character-level cnns proposed perform well text classification tasks without word embedding. introduced another character-level character embedding inputs. largest retailer china jd.com started business early satisfy merchantsâ€™ increasing demands sales. overview architecture system illustrated figure auction request arrives system recalls hundreds inventories candidates repository millions ads. ranking module ranks candidates identifies bidding method nash equilibrium position auctions extensively used world. auction winner knows place immediately behind thatâ€™s winnerâ€™s charge none losers knows anything rivalsâ€™ bid. dsps donâ€™t even know many rivals bidding auction. auction game typical game incomplete information player universal business mode dsps impressions bought cost mille sold advertisers cost click/action maximize performance. though several charging mechanisms speak paper simplicity methods discussed applicable others. used ecpm described ranking reflects business requirements advertisersâ€™ bids clicks. natural revenue expenditure must control bidding module. since using state-of-the-art ecpm bidding policy. tried calibrate click rate depicted except used factorization machine instead poisson regression calibration. ranking model structure similar wide deep models billions weights tens gigabyte memory disk space requirements meaning hardly react rapidly changing auction environment withdelay model huge update time leading design real-time impression-click data stream online learning calibration model. afterwards data stream reused ladder. handling huge amount skus hundreds millions active users tens unknown rival dsps exceeded systemâ€™s capabilities. moreover business requirements demand tradeoffs profits total revenue e.g. maximize revenue keeping certain profit margins generate economies scale. fulfill requirements introduced mechanism traffic-type level coefficients calibrated human experts. episodes. naturally define every episode. rewards. control deficits profits every auction rewards ladder. assume expense income time respectively reward auction time simplicity units related variables. notice always zero unless user click practice non-zero usually times larger considering relatively click rate function fitting extremely steep values negative small subset high positive. avoid financial loss tiny negative values positive ones must caught exactly model. implies high expressive models cnns required. actions. define actions auction game time bids happen discrete. assume ceiling actions would minimal unit result action space thousands expected sparse training data. states. high-level semantic information ğ¼ğ‘›ğ‘“ğ‘œ time active users skus ads. thatâ€™s partially observable state. generally auction formularized text description domain specific natural language according ğ¼ğ‘›ğ‘“ğ‘œ shown following example. high-level semantic information example italic notice numbers plain text. practical reason numbering rule requires similar entities close e.g. iphoneâ€™s iphone plusâ€™s seems similar experienced expert judge plain text would similar performance auction context even sheâ€™s never seen former. rnn-based models need elaborate feature engineering utilize semantic models comprise billions weights therefore large react instantly auction environment discussed earlier. contrary cnns good recognizing similar patterns. based interesting observation well definitions manage build solution. auction function generates text description ğ¼ğ‘›ğ‘“ğ‘œ example one-hot encodes text described feeds encoded content cnn. fact model works well without elaborate feature engineering thus space-efficient enough update instantly. productive model input text encoded matrix length description alphabet size. order save response time online service formulize input text sort shorthand information rather full text. also traditional architecture rather state-of-the-art inception networks resnets reason. table depicts architecture model output number linear layer omitted deliberately commercial privacy. layers except last relu activation functions. deep asynchronous stochastic q-learning algorithms inherently sequential though algorithms made possible entire episode training step still sequential nature processes acting training algorithms still serially exeportance positive rewards controlled hyper parameter also experience memory dqn. full algorithm call deep asynchronous stochastic q-learning presented algorithm auction publisher timestamp ğ¼ğ‘›ğ‘“ğ‘œ asynchronously fetch snapshot parameters probability select random otherwise select ğ‘šğ‘ğ‘¥ğ‘„âˆ— respond bidding request experiments ladder four important publishers occupy significant part revenues jd.comâ€™s business. improve revenue profits publishers experiments. experiment setup training procedure algorithm tesla gpus serving procedure servers high-performance sparse convolver. rmsprop optimize loss formula learning rate usage Îµ-greedy restricted minimize negative influence business. training decomposed phases cuted. thatâ€™s unacceptable online service must respond huge amount auctions several milliseconds. perspective training serving absolutely unfeasible needless requires hundreds times servers uneconomical. distinguishingly solve problem introducing fully decoupled parallel mechanism results fully asynchronous algorithm three processes running simultaneously without waiting other. observing also decoupled whether action would result positive reward observed asynchronously tens minutes clicked. three processes algorithm deployed threads multiple machines improve runtime performance though every auction participate shares budgets stock units state transitions auction game stochastic uncertainty user activity. consideration algorithm samples next state auction hyper parameter algorithm. besides different publishers always different roi. therefore auctions different publishers considered different games. itâ€™s challenging agent different auction games time. however training independent agents different games make states unobservable. solution requiring next state auction publisher data augmentation loss assume stochastic transition discussed above considering property auctions definition deduction would auction would lose auction. given deduction redefine rewards auction original loss formula still works especially application whose actions correlated auction games. although paper double dueling double naturally incorporated algorithm. imitation. filled experience memory data generated ecpm policy hybrid system. stage enough self-generated data memory ladder learning ecpm policy. cold-starting phase ladder interacts little environment thus ensures losses control. evaluation evaluated ladder online test overlapping experiment system similar regarded ecpm policy baseline. beginning ladder bidding auctions remaining running baseline. launched ladder auctions keep rest holdback baseline policy months sake scientific rigor. experiment system performed proportional normalization experiments ease comparison. figures shows performance comparisons ladder baseline. normalized data figures range privacy. figure shows rewards comparison ladder incurred huge losses first imitation phase tended requests exploration. soon turned second phase caught baseline next eventually outperformed baseline since notice curve well fitted curve rewards ladder. retreat launched ladder therefore experimental data mixed figure figure shows revenue growth ladder made huge improvement since first day. seems ladder learned economies scale revenues always generate profits. figure shows ladder also raised much reasonable experimented publishers basis. according holdback improvements permanent. especially jd.comâ€™s june anniversary sale ladder increased revenue publishers advertisers shown figure thus contributed growth total revenue jdâ€™s business total sale. improvement sale proves adaptability responsiveness ladder highly volatile competitive environment. exploration exploitation hyper parameter controls balance exploration exploitation. maximize revenues launched deployment figures depict decrease revenue decrease rewards increase means agent tends explore less aggressively. visualization order figure ladderâ€™s capability understanding high-level semantic information embedded plaintext description inputs t-sne visualize outputs hidden layer. analysis angles. multiple games single model mentioned earlier ladder serves different publishers simultaneously. although challenging figure shows ladder successfully learned plain-text inputs difference publishers. surpassed baseline revenue publisher evaluated. technically verify well ladder distinguish different publishers publisher type label visualize random samples figure expected publishers mapped separate clusters perfectly. complex semantic figure samples publisher scatter several clusters. fact ladderâ€™s learned semantic much complex publisher ids. analysis visualize data publisher samples. figure shows ladder learned rather complex conditions plain-text inputs essential auction. e.g. skus delivered logistic network attractive cold-start user jdln well-known feature superior user experience. left part figure indicates ladder recognizes situations. real-time online auctions large scale real world problems human-level agents excel. considering adxs mimics stock exchanges applying ladder quantitative trading also great interest challenge. present reinforcement learning agent namely ladder paper solving auction game dsp. create human-level agent capable saving manpower performing well even better humans also directly understanding situation auction plain-text description human experts result ladder reach goal easily outperforming existing industrial state-of-theart solution tests means made full high-level semantic information auction game without sophisticated feature engineering reacts changing auction environment immediately. also introduce dasqn asynchronous stochastic q-network totally decouples learning observing acting processes q-learning hence greatly improving run-time performance enabling algorithm solve large scale real-world problems.", "year": 2017}