{"title": "Resting state fMRI functional connectivity-based classification using a  convolutional neural network architecture", "tag": ["stat.ML", "cs.CV", "cs.LG", "68T99", "I.5.1; I.5.2"], "abstract": "Machine learning techniques have become increasingly popular in the field of resting state fMRI (functional magnetic resonance imaging) network based classification. However, the application of convolutional networks has been proposed only very recently and has remained largely unexplored. In this paper we describe a convolutional neural network architecture for functional connectome classification called connectome-convolutional neural network (CCNN). Our results on simulated datasets and a publicly available dataset for amnestic mild cognitive impairment classification demonstrate that our CCNN model can efficiently distinguish between subject groups. We also show that the connectome-convolutional network is capable to combine information from diverse functional connectivity metrics and that models using a combination of different connectivity descriptors are able to outperform classifiers using only one metric. From this flexibility follows that our proposed CCNN model can be easily adapted to a wide range of connectome based classification or regression tasks, by varying which connectivity descriptor combinations are used to train the network.", "text": "keywords classification convolutional neural network dynamic time warping resting state connectivity connectome functional magnetic resonance imaging machine learning techniques become increasingly popular field resting state fmri network based classification. however application convolutional networks proposed recently remained largely unexplored. paper describe convolutional neural network architecture functional connectome classification called connectome-convolutional neural network results simulated datasets publicly available dataset amnestic mild cognitive impairment classification demonstrate ccnn model efficiently distinguish subject groups. also show connectome-convolutional network capable combine information diverse functional connectivity metrics models using combination different connectivity descriptors able outperform classifiers using metric. flexibility follows proposed ccnn model easily adapted wide range connectome based classification regression tasks varying connectivity descriptor combinations used train network. resting state functional become popular techniques investigation human brain‚Äôs functional connectivity studying resting state fmri functional connectome offers unique understand large scale functional organization human brain health disease. shown recently efficacy resting state fmri network based classification improved substantially using machine learning techniques raised intriguing possibility application machine learning fast objective diagnosis mental disorders autism schizophrenia major depressive disorder cognitive impairment vast majority machine learning studies used traditional algorithms classification support vector machines least absolute shrinkage selection operator recent review encompassing based machine learning papers half articles proposed svms. svms many advantages especially relatively small datasets models resist overfitting well another popular method applies lasso linear regression technique enforces sparsity weights sparsity dual advantages prevents overfitting high-dimensional featurespaces creates well-interpretable results selecting relatively number important features. however recent developments deep learning methods theory shows especially case complex high-dimensional datasets fmri data deep models exponential gain efficiency traditional machine learning models i.e. amount training data deep neural networks learn exponentially complex output function traditional linear kernel methods arguably great potential lies application deep learning techniques fmri based classification indeed fully connected deep neural networks successfully applied fmri volume classification well functional connectivity based classification furthermore recent results show convolutional neural network architectures might also used connectome based classification appears especially important light remarkable success convolutional neural networks image classification object recognition; e.g. famous imagenet challenge however successful application deep convolutional networks connectome based data classification holds number substantial challenges must overcome. important requirement deep learning techniques availability large amount training examples appears serious concern since structural functional studies number measurements compared number examples datasets used object recognition image classifiers work extremely well tens neural layers millions trainable weights however small sample size results overfitting large networks even careful regularization. therefore case connectome based applications relatively simple convolutional network architectures designed correspondence amount available data. another success deep convolutional networks weight sharing different image regions. particular convolutional networks able learn properties given pixel‚Äôs local neighborhood structure independent localization pixel. sharing weights simplifies network makes robust overfitting reducing number trainable weights case fully connected layer design image e.g. pixels output neurons million trainable weights convolutional layer patches filters additionally learnt representation becomes shift invariant crucially important factor object recognition. appropriate architecture training design types invariance achieved like rotational scale invariance also beneficial results several applications. task classification based brain connectivity data shows remarkable similarities image classification. structural functional connectomes represented matrices column corresponds voxel cases brain region given parcellation scheme value entry matrix describes connectivity i-th j-th brain region. matrices treated images matrix entries analogous pixels. however structure local neighborhood connectome data equivalent traditional image datasets patterns recognize case means shift invariant local neighborhoods mean little ordering rois necessarily interpretable. connectome data based learning consider graph structure behind connectivity matrix determine share weights i.e. brain graphs usually fully connected neighborhood contains every region convolutional filters designed take account. application convolutional architectures connectome data early stage recent study authors proposed three types convolutional filters structural connectome data edge-to-edge edge-to-node node-to-graph filters different combinations column wise convolutional filters. brinnetcnn architecture takes tractography-based connectivity matrices input used estimate continuous variables like subject behavioral metrics. however important feature convolutional network architectures exploited study. convolutional networks designed able treat single grayscale images combine information color channels different channels hold information different aspects pixel information smartly combined together learned weights network. similarly networks straightforwardly combine connectivity matrices different metrics keeping information features correspond pairs treating connectivity matrices color channels standard image processing tasks. present study aimed investigating application convolutional networks functional connectome classification using simple connectivity fingerprint-based convolutional filter. ccnn model treated rois whole connectivity fingerprint i.e. matrix unit weights shared across whole connectivity matrix. rationale behind approach following assume regions show altered connectivity classes differentiate learned convolutional filter distribute large weights rois i.e. convolve every rois‚Äô fingerprint filter connectivity strength altered regions large influence output. proposed filters output value roi‚Äôs connectivity fingerprint number trainable weights equals number rois. based output value calculated sequentially applying edge-to-node node-to-graph filter connectivity matrix. however using filter combination requires training three times many weights ours largely increasing size neural network model lead aforementioned disadvantages number training examples low. addition implementing convolutional filter also tested hypothesis combination different functional connectivity metrics improve classification accuracy. assumed even though using combined inputs naturally increase number trainable weights model adding sources information might still increase classification performance. traditionally functional connectivity strength measured using correlation coefficient calculation. however several additional methods proposed grasp dynamic properties functional connectivity purpose classification desirable connectivity matrix stable measurements shown correlation coefficients resting state time-series dynamically changing alternating brain states overcome problem recently proposed dynamic time warping distance warping path length metrics functional connectivity strength phase stability. distance handle correct dynamically changing phase-relationships brain regions able demonstrate distance based connectivity strength calculation indeed results stable connectivity measurements length warping path provides important additional information connection stability previous papers also showed distance warping path length successfully used connectivity based classification distance warping path length describe complementary aspects connectivity current study examine effect combination different functional connectivity metrics classification accuracy convolutional network combining input measures compare classification performance results based single connectivity features calculated three metrics correlation distance warping path length. paper demonstrate feasibility convolutional model ccnn simulated dataset test proposed approach publicly available datasets amnestic mild cognitive impairment classification compared performance traditional neural network hidden layer deep neural network. demonstrate connectome-convolutional network architecture outperforms simple neural network deep model cases best performing models ccnns combination different connectivity metrics. used publicly available data consortium reliability reproducibility dataset datasets contain forty-nine subjects older years years diagnosed amci) subject participated least -sec-long resting-state fmri measurements subjects resting-state measurements total. dataset collected institute clinical radiology ludwig-maximilians-university munich germany philips achieva scanner high-resolution anatomical images acquired subject using t-weighted sequence total functional images collected bold-sensitive weighted gre-epi sequence axial slices acquired ascending acquisition order covering whole brain. details available website datasets preprocessing imaging data performed using toolbox custom-made scripts running matlab subject‚Äôs functional images motion-corrected images sessions spatially realigned mean image. then images spatially smoothed using full-width half maximum gaussian filter. anatomical images coregistered mean functional images used realignment step. coregistered images segmented using unified segmentation normalization tool spm. resulting grey matter mask later used restrict analysis images voxels; white matter cerebrospinal fluid masks used extract nuisance signals unlikely reflect neural activity resting-state time-series. realigned coregistered images normalized mni- space using transformation matrices generated segmentation normalization anatomical images. regressing head-motion parameters mean mean signals residual time courses voxels band-pass filtered using combination temporal high-pass low-pass filters retain signals within range calculate roi-based whole-brain functional connectivity used willard functional atlas find consisting functional regions interest obtain functionally meaningful averaged bold signals measurement. time series calculate full connectivity matrices leading independent pairwise connectivity features. functional connectivity characterized various metrics including traditional correlation coefficient dynamic time warping distance warping path length brief description based methods supplementary material. demonstrate strengths proposed convolutional filters created artificial dataset connectome matrices. base connectome choose random correlation based functional connectome healthy subject created three modified versions healthy connectome based connectome matrix patient amci. generated modifications replacing rows columns corresponding randomly chosen rois healthy connectome rows columns amci connectome specifically created connectomes five rois replaced. unchanged healthy connectome modified connectome created replicas added random gaussian noise connectomes generate unique instances taking account matrices stay symmetrical added noise different weights i.e. normalized noise values maximal absolute value added noise weights ranging ten. three modification levels weight-levels added noise created altogether thirty simulated datasets. aimed classify simulated datasets amnestic mild cognitive impairment based functional connectivity data. estimate classification performance applied cross-validation. amci dataset instances measurements subjects independent therefore took account cross-validation. dataset measurements subjects applied -fold cross-validation randomly divided subjects seven folds fold contains measurements subjects assigned fold. used partitioning evaluate classifiers. simulated datasets unique instances therefore applied simple -fold cross-validation. asses classification performance primarily accuracy classes balanced classification tasks present detailed information calculated area receiver operator characteristics curve well. achieve better classification performance designed novel convolutional network architecture ccnn functional connectivity pattern classification. traditional convolutional networks usually apply square weight patches convolution image classification important information contained square neighborhoods pixels. functional connectivity classification arranged connectivity features matrices apply convolution layers first line-by-line column second convolution layer provides input fully connected hidden layer neurons feeds output neurons corresponding classes first convolutional layer train filters second convolutional layer filters. means first convolutional layer extracts features i.e. calculate differently weighted sums roi‚Äôs connectivity fingerprint. second layer reduces dimensionality further outputs feature instance dimensional feature vector serves input fully connected layer. around instances datasets means number extracted features approximately matched number instances. convolutional neural network applied rectified linear unit non-linearity output layer apply softmax function calculate probability instance belonging class. binary classification could output neuron determine probability instance belonging positive class however adopted approach neuron class softmax function straightforwardly implemented multiclass classification tasks well. train robust classifier applied drop-out regularization keeping probability adam optimizer case combined ccnn classifiers input consists matrices connectivity features considered channel apply convolution channels i.e. matrices simultaneously similarly convolutional layers work channels colored images. approach explicitly inform network connectivity features belong pair algorithm take advantage additional information well. worth note size ccnn increases less percent addition channel. original network altogether *+**+*+* trainable weights plus biases channels ccnn **+**+*+* trainable weights plus biases. simple baseline random classification applied binomial method described class classification random classifier chance predicting true label therefore probability obtaining correct labels trials calculated cumulative binomial distribution function threshold significance choose percentile i.e. searched value ùêπùêµùëñùëõùëúùëö baseline accuracy calculated case simulated dataset calculated baseline accuracy ùêπùêµùëñùëõùëúùëö amci dataset threshold significance ùêπùêµùëñùëõùëúùëö stricter baseline classification result available connectivity datasets created traditional neural network containing input layer input neurons hidden layer neurons output neurons classes hidden layer sigmoid nonlinearity output layer apply softmax function calculate probability instance belonging class. network trained stochastic gradient descent cross-entropy loss function refer network simple neural network. number trainable weights network equals plus biases almost four times ccnn model. case combined classifiers learn connectivity descriptors thus number input neurons equals therefore number trainable weights nearly doubles plus biases. demonstrate convolutional architecture performs compared state-of-the-art neural network architecture created multi-layered neural network. input layer similar simple neural network consists neurons depending whether data single connectivity descriptor combine metrics. first hidden layer neurons i.e. layer extracts features instance similar convolutional layers ccnn architecture. second hidden layer contains neurons similarly convolutional networks‚Äô fully connected layer lastly multi-layered neural network output neurons simple convolutional architecture neural network classifier applied relu nonlinearities hidden layers softmax output layer drop-out regularization keeping probability adam optimizer similarly convolutional neural network i.e. primary source differences models convolutional architecture. neural network multi-layered applied aforementioned deep learning techniques training refer deep neural network classifier throughout paper. number trainable weights deep neural network *+*+* plus biases slightly simple neural network. case combined input data number trainable weights almost doubles well *+*+* plus biases. figure architecture simple neural network classifier architecture deep neural network classifier architecture proposed connectome-convolutional neural network model results section describe classification results performance metrics accuracy area receiver operator characteristics curve determine difference classifiers‚Äô performance significant applied binomial test consider difference significant calculated p-value lower also visualized best performing classifiers learned available data. fig. summarized classification accuracies achieved simple neural network deep network proposed connectome-convolutional architecture function number modified rois level noise. expected results revealed classification performance simple neural network increases number modified rois decreases weight added noise increases. fully connected deep neural network clearly outperform simple architecture cases interestingly shows near random performance noise level relatively likely overfitting. results clearly show ccnn architecture best overall performance significantly outperforming even deep neural network several cases. weight sharing considerably reduces number trainable weights figure accuracies classification simulated data simple deep connectome-convolutional neural networks. black dashed line represents random baseline significant differences deep connectome-convolutional networks‚Äô results denoted stars. classification accuracies dataset modified classification accuracies dataset five rois modified classification accuracies rois modified besides demonstrating connectome-convolutional neural network‚Äôs remarkable performance robustness also showed based first layer‚Äôs weights neural networks indeed recover rois played important role classification. investigated hypothesis learnt convolutional filters distribute high absolute value weights rois behave differently classes i.e. rois largest absolute values first convolutional layer‚Äôs filters overlap ones actually modified simulated datasets. naturally keep mind ccnn layers fact rois large weights first layer mean play significant role classification filter outputs weighted next layer. evaluated hypothesis noise level five still ccnns able classify data better random added noise large weight. experiment showed based dataset modified classes connectome-convolutional architecture distributed largest absolute values altered roi. case dataset five rois modified ccnn model identified four among five rois largest absolute weight. dataset rois altered also four rois could recovered. learnt weights first layer connectome-convolutional networks visualized supplementary fig. table shows performance examined neural networks amnestic mild cognitive impairment classification simple neural networks deep neural networks connectomeconvolutional neural networks using various feature sets pairwise correlation coefficients distances warping path length features combination latter feature sets. first compared classification performances random baseline i.e. threshold significance accuracy dynamic time warping based measures outperform threshold i.e. path length based classification achieved significant results simple deep ccnn architecture distance based classification successful deep connectome-convolutional neural network. also interesting compare whether differences performance simple neural model ccnn significant. found difference case correlation based classifiers also case path length based classifier although case ccnn‚Äôs accuracy substantially higher simple neuronal network. difference classification performance significant case distance based classifiers p=.. comparing results deep connectomeconvolutional neural network found even though ccnn systematically outperforms deep model differences significant classifiers based single connectivity feature sets best classification performance achieved distancebased ccnn model. next tested whether training connectome-convolutional neural networks using combination connectivity feature sets based distance warping path length leads better classification performance compared previous models. combined ccnn model achieved higher classification performance threshold random classification. significantly outperformed simple neural network trained combined features importantly difference deep connectome-convolutional neural networks‚Äô results also showed high significance also compared performance ccnn trained combined data performance ccnns trained type connectivity features. classification performance combined model significantly higher warping path length based connectome-convolutional network differ significantly distance based model‚Äôs performance results combined models overall best classification performance achieved ccnn trained distance warping path length data. demonstrated simulated dataset weights connectome-convolutional neural network identify rois played important role classification. combined distance path length based ccnn model achieved overall best performance analyzed weight distribution model i.e. weights first convolutional layer first weights correspond distance features second weights correspond warping path length values. sake biological interpretation aimed incorporate meaningful information learned weights i.e. trained ccnn architecture combined feature whole dataset. figure learned weights first convolutional layer combined ccnn model trained whole amci dataset. layer weights present first weights corresponding distance values separately second weights correspond warping path length features colormap first weights first convolutional layer combined ccnn model corresponding distance features. determine rois play important role classification summarized absolute values weights filters. high values represent rois significant effect filters. determine filters effective summarized absolute values weights rois. high values represent filters substantial influence output. colormap second weights first convolutional layer combined ccnn model corresponding relative warping path length features. summarized absolute values weights filters. high values represent rois significant effect filters. summarized absolute values weights rois. high values represent filters substantial influence output. fig. clearly visible rois high absolute value weights filters i.e. connectivity brain areas important effect output first layer. note important rois warping path length significant overlap. although distance warping path length correlate measure substantially different aspects co-activity distance measures connectivity strength whereas waring path length quantifies stability connection i.e. frequently phase difference changes rois. distance based features right amygdala hippocampus bilateral caudate left putamen anterior medial cingulate cortex dorsolateral prefrontal cortex temporal occipital regions show alterations classes path length features medial regions bilateral thalamus left caudate posterior cingulate cortex precuneus dorsolateral prefrontal cortex insula occipital frontal areas play important role classification according amci figure influential rois based first convolutional layer‚Äôs weights amci classification ccnn. important rois based distance features important rois based warping path length features results present study clearly show using convolutional neural architectures connectome classification great potential even case relatively small sample sizes. demonstrated proposed ccnn architecture significantly outperform traditional neural network deep neural network model well. simulation study able prove connectome-convolutional network much less prone overfitting deep model systematically outperforms deep simple neural architectures different noise modification levels. also showed analyzing brain regions largest absolute weights convolutional filters first layer indeed recover rois contained amnestic mild cognitive impairment classification ccnn model also systematically outperformed deep simple neural networks importantly connectome-convolutional network able utilize information multiple different connectivity metrics. case difference ccnn model second best performing deep neural network highly significant likely result fact doubling number input features size deep neural network also doubles size ccnn architecture slightly increases consequently convolutional networks less prone overfitting exploit additional information efficiently feature great potential future research ccnn model benefit different functional connectivity metrics example straightforwardly combine structural functional connectivity information well. thorough comparison also performed experiments traditionally well performing machine learning models. extremely high number features combined distance warping path length dataset applied methods accomplish feature selection linear classifier combined anova f-test based feature selection lasso model results experiments showed lasso perform better deep neural network given relatively number samples however neither methods achieved better results proposed ccnn architecture. although best performing approach achieved less accuracy ccnn model argue proposed method holds much greater promises small performance gain. sample size fmri experiments continues increase multimodal paradigms also gain popularity performances ccnn model similar deep learning based techniques traditional machine learning methods bound increase amnestic mild cognitive impairment classification performance based distance integrates dynamic connectivity warping path length describes phase-stability significantly higher based correlation coefficients. agreement recent findings showing strong alterations dynamic connectivity connection stability alzheimer‚Äôs disease mild cognitive impairment best performance achieved ccnn trained combination metrics namely distance path length. influential regions classification include regions default mode network executive control network well several subcortical regions including hippocampus basal ganglia amygdala. results close agreement previous research providing converging evidence abnormalities resting-state functional connectivity regions amnestic mild cognitive impairment previous findings shown classification based distance warping path length outperform correlation based paradigm different datasets even different classifiers classification targets results presented paper also confirm taking account dynamic properties functional connectivity assist classification. distance path length based classifiers outperform correlation based models best results achieved combining connectivity features metrics. understand combination connectivity descriptors leads better results important notice distance warping path length related. case strong connections i.e. compared time-series similar almost warping necessary thus length warping path short calculated distance close zero. additionally case independent random time-series distance large series cannot meaningfully matched also independent time-series mean editing steps therefore length warping path increases well however connections dynamic time warping algorithm generate good match time-series phase relationship unstable i.e. time-delay structure dynamically changing measurement. type relationship result long warping path lengths despite relatively distance values connections warping path length contains interesting additional information naturally deep learning techniques particularly ccnn method drawbacks well. deeper networks take longer time train traditional shallow neural networks methods like svms however modern deep learning frameworks computing ccnn model trained sevenfold cross-validation within hour. another difficulty selection hyperparameters. deep networks several architectural parameters like number different convolutional fully connected layers number filters neurons layer activation function well training parameters like initialization loss-function learning-rate optimization function. long training time models thorough hyper-parameter learning usually feasible typically small number parameters tuned parameters based experience also note even though convolutional architectural design significantly decrease number trainable parameters compared fully connected deep networks number trainable weights still high compared number samples dataset. therefore careful regularization essential success models effectiveness application datasets extremely training examples debatable. paper presented connectome-convolutional neural network architecture designed able analyze bran connectivity matrices classify subject groups based connectivity fingerprints brain regions. experiment simulated datasets showed besides high classification performance ccnn architecture implemented identify rois altered connectivity strength values. real-world dataset healthy elderly controls patients amnestic mild cognitive impairment also able demonstrate connectome-convolutional neural network effectively utilize information multiple functional connectivity descriptors. namely overall best classification accuracy achieved ccnn model trained combination dynamic time warping distance warping path length connectivity matrices. brain regions large influence classification results well aligned current research findings amnestic mild cognitive impairment. results conclude presented connectome-convolutional neural network architecture considered efficient tool brain connectivity-based classification tasks especially experiments multiple connectivity descriptors i.e. different functional connectivity measures functional structural connectivity information available. work supported grant hungarian brain research program zolt√°n vidny√°nszky. krisztian buza supported national research development innovation office nkfih j√°nos bolyai research scholarship hungarian academy sciences. abraham milham martino craddock samaras thirion deriving reproducible biomarkers multi-site resting-state data autism-based example. neuroimage doi./j.neuroimage.... arbabshirani kiehl pearlson calhoun classification schizophrenia patients based resting-state functional network connectivity. front. neurosci. doi./fnins... bengio delalleau roux curse highly variable functions local kernel machines. proceedings international conference neural information processing systems nips‚Äô. available http//dl.acm.org/citation.cfm?id=. blautzik vetter peres gutyrchik keeser berman classifying fmri-derived resting-state connectivity patterns according daily rhythmicity. neuroimage doi./j.neuroimage.... bridle probabilistic interpretation feedforward classification network outputs relationships statistical pattern recognition neurocomputing nato series. eds. souli√© h√©rault available http//link.springer.com/chapter/./----_ brown rudie bandrowski horn bookheimer ucla multimodal connectivity database web-based platform brain connectivity matrix sharing analysis. front. neuroinformatics doi./fninf... chen chang greicius glover introducing co-activation pattern metrics quantify spontaneous brain network dynamics. neuroimage doi./j.neuroimage.... c√≥rdova-palomera kaufmann persson aln√¶s doan moberget disrupted global metastability static dynamic brain connectivity across individuals alzheimer‚Äôs disease continuum. sci. rep. doi./srep. fransson marrelec precuneus/posterior cingulate cortex plays pivotal role default mode network evidence partial correlation network analysis. neuroimage doi./j.neuroimage.... greicius krasnow reiss menon functional connectivity resting brain network analysis default mode hypothesis. proc. natl. acad. sci. doi./pnas.. jang plis calhoun j.-h. task-specific feature extraction classification fmri volumes using deep neural network initialized deep belief network evaluation using sensorimotor tasks. neuroimage doi./j.neuroimage.... kassraian-fard matthis balsters maathuis wenderoth promises pitfalls basic guidelines applying machine learning classifiers psychiatric imaging data autism example. front. psychiatry doi./fpsyt... kawahara brown miller booth chau grunau brainnetcnn convolutional neural networks brain networks; towards predicting neurodevelopment. neuroimage doi./j.neuroimage.... calhoun shim j.-h. deep neural network weight sparsity control pre-training extracts hierarchical features enhances classification performance evidence whole-brain resting-state functional connectivity patterns schizophrenia. neuroimage part doi./j.neuroimage.... krizhevsky sutskever hinton imagenet classification deep convolutional neural networks advances neural information processing systems eds. pereira burges bottou weinberger available http//papers.nips.cc/paper/-imagenet-classification-with-deepconvolutional-neural-networks.pdf liang wang yang functional disconnection compensation mild cognitive impairment evidence dlpfc connectivity using resting-state fmri. plos doi./journal.pone.. liang chen zhao disrupted functional connectivity related differential degeneration cingulum bundle mild cognitive impairment patients. curr. alzheimer res. liem varoquaux kynast beyer kharabian masouleh huntenburg predicting brain-age multimodal imaging data captures cognitive impairment. neuroimage doi./j.neuroimage.... meszl√©nyi hermann buza vidny√°nszky resting state fmri functional connectivity analysis using dynamic time warping. front. neurosci. doi./fnins... meszl√©nyi peska vidny√°nszky buza model classification based functional connectivity pattern dynamics brain. third european network intelligence conference doi./enic... meszl√©nyi peska vidny√°nszky buza classification fmri data using dynamic time warping based functional connectivity analysis. european signal processing conference doi./eusipco... mont√∫far pascanu bengio number linear regions deep neural networks. proceedings international conference neural information processing systems nips‚Äô. available http//dl.acm.org/citation.cfm?id=. richiardi altmann milazzo a.-c. chang chakravarty banaschewski brain networks. correlated gene expression supports synchronous activity brain networks. science doi./science.. rosa portugal hahn fallgatter garrido shawe-taylor sparse network-based models patient classification using fmri. neuroimage doi./j.neuroimage.... salvador suckling schwarzbauer bullmore undirected graphs frequency-dependent functional connectivity whole brain networks. philos. trans. soc. biol. sci. doi./rstb... szegedy sermanet reed anguelov going deeper convolutions. available http//www.cvfoundation.org/openaccess/content_cvpr_/html/szegedy_going_deeper_with__cv pr_paper.html tomasev buza marussy hubness-aware classification instance selection feature construction survey extensions time-series feature selection data pattern recognition vieira pinaya mechelli using deep learning investigate neuroimaging correlates psychiatric neurological disorders methods applications. neurosci. biobehav. rev. part doi./j.neubiorev.... wager wang liang dropout training adaptive regularization advances neural information processing systems eds. burges bottou welling ghahramani weinberger available http//papers.nips.cc/paper/-dropout-training-as-adaptive-regularization.pdf yang song huang chen voxelwise metaanalysis gray matter anomalies alzheimer‚Äôs disease mild cognitive impairment using anatomic likelihood estimation. neurol. sci. doi./j.jns.... x.-n. anderson bellec birn biswal blautzik open science resource establishing reliability reproducibility functional connectomics. sci. data doi./sdata... dynamic time warping time-series distance measure correct even dynamically changing phase-differences signals. first applied field speech recognition distance efficiently used time-series classification recently group demonstrated potential fmri data analysis called edit distance means measures cost transforming timeseries editing steps possible transforming timeseries replacement element element elongation element cost editing step difference matched elements overall cost transformation costs editing step distance minimal possible transformation cost. calculate distance length filling entries matrix column-by-column row-by-row based equation denotes i-th value time series denotes j-th value time series dtw-distance time series constrain maximal allowed phase-difference speed-up dtw-calculations calculate entries matrix close main diagonal maximal allowed time-shift called warping window filling-in matrix reconstruct editing steps minimal distance value i.e. determine optimal matching element time series optimal matching sequence called warping path comparing identical time-series warping path exactly follows main diagonal phase-differences signals introduce elongation steps therefore length warping path increase compared main diagonal. difference warping path length length main diagonal characterize overall phase difference stability time-delay structure time-series measure referred warping path length throughout paper. supplementary figure figure adapted time series compared i-th element elastically matched appropriate element filleddtw matrix plotted heat-map denotes size warping window maximal allowed time-lag matched time series element. main diagonal represented dark line optimal warping path plotted red. time-delay time series given time-point given warping path‚Äôs deviation main diagonal calculation distance filling matrix example shows first element time series elements corresponds rows elements corresponds columns matrix. optimal warping path highlighted dark grey. formula calculate entry example entry squared distance plus minimum matrix entries optimal matching first elements revealed matrix. also tested traditional machine learning methods perform compared ccnn method. conducted experiments algorithms handle curse dimensionality feature selection namely linear classifier combined anova f-test based feature selection described lasso model also frequently used fmri based classification adopted approach detailed ccnn method‚Äôs best result achieved combination connectivity features distance path length calculated baseline accuracies dataset different hyperparameter setups lasso models. based results presented supplementary table conclude neither methods could achieve better performance ccnn model. also note resulting predictions different hyper-parameter setups differ significantly neural network models trained extract features connectivity data selected best connectivity features based anova ftests performed linear classification selected features five different values complexity parameter accuracy values summarized supplementary table case lasso model based classification experiments values regularization hyper-parameter enforce selection approximately connectivity features. supplementary table summarizes accuracy values resulting classifications well mean standard deviation number selected features seven folds cross-validation. ccnn method achieved considerably better accuracy combined dataset dataset containing single connectivity feature therefore also important examine whether lasso models similarly well utilize information multiple connectivity features. consequently conducted classification experiments lasso models based three single connectivity feature datasets correlation distance warping path length. similarly training combined dataset selected best connectivity features based anova f-tests performed linear classification selected features accuracy values summarized supplementary table combined distance warping path length dataset best accuracy lower ccnn result case lasso classifiers best performing model lower accuracy ccnn model however neither differences significant since experiments different hyper-parameters estimates test-performances might over-optimistic. even slight positive bias none classifiers achieved better results ccnn model. importantly note neither lasso model able utilize additional information combination different connectivity features i.e. classifier even achieved slightly better accuracy single distance dataset combined data lasso model result single path length combined datasets. results confirm convolutional model able integrate information multiple different connectivity features traditional machine learning algorithms gain performance additional information. furthermore based current deep learning research assume growing number measurements growing number measured dimensions i.e. case increasingly complex data difference performance traditional machine learning models deep learning methods increase therefore proposed ccnn architecture hold great potential future research. supplementary figure learned weights first convolutional layer ccnn model trained whole simulated dataset modification. colormap weights first convolutional layer. determine rois play important role classification summarized absolute values weights filters. high values represent rois significant effect filters sole highest peak indeed identical altered determine filters effective summarized absolute values weights rois. high values represent filters substantial influence output. learned weights first convolutional layer ccnn model trained whole simulated dataset five modification. colormap weights first convolutional layer. summarized absolute values weights filters. four five highest peaks overlap modified five rois. summarized absolute values weights rois. learned weights first convolutional layer ccnn model trained whole simulated dataset modification. colormap weights first convolutional layer. summarized absolute values weights filters. four highest peaks overlap modified rois. summarized absolute values weights rois. ding trajcevski scheuermann wang keogh querying mining time series data experimental comparison representations distance measures. proc vldb endow doi./.. meszl√©nyi hermann buza vidny√°nszky resting state fmri functional connectivity analysis using dynamic time warping. front. neurosci. doi./fnins... meszl√©nyi peska vidny√°nszky buza model classification based functional connectivity pattern dynamics brain. third european network intelligence conference doi./enic... meszl√©nyi peska vidny√°nszky buza classification fmri data using dynamic time warping based functional connectivity analysis. european signal processing conference doi./eusipco... rosa portugal hahn fallgatter garrido shawe-taylor sparse network-based models patient classification using fmri. neuroimage doi./j.neuroimage.... keogh shelton ratanamahatana fast time series classification using numerosity reduction. proceedings international conference machine learning icml doi./..", "year": 2017}