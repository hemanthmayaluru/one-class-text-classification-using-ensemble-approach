{"title": "CNN Is All You Need", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "The Convolution Neural Network (CNN) has demonstrated the unique advantage in audio, image and text learning; recently it has also challenged Recurrent Neural Networks (RNNs) with long short-term memory cells (LSTM) in sequence-to-sequence learning, since the computations involved in CNN are easily parallelizable whereas those involved in RNN are mostly sequential, leading to a performance bottleneck. However, unlike RNN, the native CNN lacks the history sensitivity required for sequence transformation; therefore enhancing the sequential order awareness, or position-sensitivity, becomes the key to make CNN the general deep learning model. In this work we introduce an extended CNN model with strengthen position-sensitivity, called PoseNet. A notable feature of PoseNet is the asymmetric treatment of position information in the encoder and the decoder. Experiments shows that PoseNet allows us to improve the accuracy of CNN based sequence-to-sequence learning significantly, achieving around 33-36 BLEU scores on the WMT 2014 English-to-German translation task, and around 44-46 BLEU scores on the English-to-French translation task.", "text": "convolution neural network demonstrated unique advantage audio image text learning; recently also challenged recurrent neural networks long short-term memory cells sequence-tosequence learning since computations involved easily parallelizable whereas involved mostly sequential leading performance bottleneck. however unlike native lacks history sensitivity required sequence transformation; therefore enhancing sequential order awareness position-sensitivity becomes make general deep learning model. work introduce extended model strengthen position-sensitivity called posenet. notable feature posenet asymmetric treatment position information encoder decoder. experiments shows posenet allows improve accuracy based sequence-to-sequence learning significantly achieving around bleu scores english-to-german translation task around bleu scores english-tofrench translation task. cnns successfully used audio image text classification analysis generation whereas rnns lstm cells widely adopted solving sequence transduction problems language modeling machine translation models typically align element positions input output sequences steps computation time generating sequenced hidden states depending current element previous hidden state. operations inherently sequential precludes parallelization becomes performance bottleneck. situation motivated researchers extend easily parallelizable models efficient sequence-to-sequence mapping. efforts deliver satisfactory quality usage deep learning would significantly broadened. compared learning convolution models provide means efficient non-local referencing across time steps without fully sequential processing allowing computations whole sequence concurrent rather element time maximizing gpu’s capability orders magnitude performance gain. convolution generally conducted matrix operations batches records. capture element-wise sequential context record-level processing several mechanisms proposed recently position encoding kernel dilation attention convss xception bytenet wavenet slicenet reduce number parameters hence computation cost additional optimizations depth-wise convolution multi-head attention introduced commonly characterized dividing work focus enhancing position-sensitivity based sequence-tosequence learning framework explore distinguish various operational phases apply right mechanisms right contexts maximizing expected benefits minimizing unwanted side-effects. specifically encapsulate group neurons convolutions convolution whose activity vector represents instantiation parameters similar treatment found basic building blocks architecture. using convolution boxes encoder decoder customize internal structures depending used different sub-layers dealing sequential position information corresponding context. notable feature approach asymmetric treatment position information encoder decoder. according difference sequential information presented used encoding decoding processes repeat positionencoding along multiple layers encoder; apply dilation convolution encoding regular convolutions decoding organize self-attention cross-attention position-wise feed-forward customized residual links selectively encoder decoder. implement context-sensitive position-sensitive mechanisms extended model posenet improving accuracy convolution based sequence-to-sequence learning. experiments show using posenet allows achieve around approximate bleu scores english-to-german translation task batch-size training steps well superior performance english-to-french translation achieving approximate bleu scores batch-size training steps. similar also enhanced accuracy attention-only approach extended model actually outperforms posenet described tasks; however believe certain areas image recognition provide higher generality work focus exploring universal particularly sequence-to-sequence learning efforts reported separately. encoder-decoder architectures encoder processes input sequence elements returns internal representations decoder takes generate output sequence left right element time. based sequence-to-sequence learning computed sequentially kept revisable long short history. generate output decoder computes hidden state based previous state previous output well conditional input derived encoder output models without attention consider final encoder state either ignoring setting position architectures attention compute weighted time-step corresponding attention scores focusing different parts input sequence. attention scores computed comparing encoder state combination previous decoder state last prediction element; result normalized distribution input elements based sequence-to-sequence transformation follows high-level scenario general intermediate encoder decoder representations calculated convolutions parallel input output positions. usually encoder decoder networks stacked kind convolution layer computes intermediate representations based fixed number input elements. stacking several layers increases range input elements represented. further convolutions often followed non-linearities allowing networks focus wider input field. padding employed encoding decoding sequence transduction tasks sense sequence represented long-range dependencies. important factor affecting ability learn dependencies length paths combination positions input output sequences signals traverse forward backward network; shorter paths easier learn longrange dependencies. point view convolution provides advantage sequence-to-sequence learning since multi-layer convolution stack create multi-level representations input sequence nearby input elements interact lower levels distant elements interact higher levels hierarchical structure modeled provides shorter paths compared chain structure modeled rnn. kernels width feature representation capturing relationships within window elements accessed applying convolution operation compared linear number rnn. further based sequence mapping naturally parallelized since inputs constant number kernels non-linearities whereas number operations non-linearities applied varies position position. onvolution like deep learning operations essentially tensor-to-tensor mapping. sequence transformations positional relationships elements handled along matrix manipulation tensors. sequence-to-sequence learning input target record consists sequence elements along time-steps. common deep learning model make order elements inject information relative absolute position elements sequence typically input elements first embedded distributional space depth equip model sense absolute position input elements encoded forming combined input element representation target elements processed similarly encoding phase. note positional encodings form tensor depth input embeddings summed. usually positional encodings added input embeddings bottoms encoder decoder stacks. since position encoding gives model sense order input target sequence currently dealing with explored repeat appropriate layers model graph strengthen position sensitivity multiple layers without introducing unexpected noises. encoding/decoding sequence-to-sequence mapping essentially consists determining positional correlation input/target pairs position-wise feed-forward networks come picture. similar convolution kernel size applied position separately identically. n-layer ffnn performs linear transformations relu activation between intuitively described below. although linear transformations across different positions position awareness transformations different parameters layer layer. therefore adding appropriate points model graph provides enhance position sensitivity. filter dilation mechanism correlating distant elements convolutional sequence-tosequence autoregressive approach. essentially filter dilation increases receptive field convolution operation enlarging spatial extent feature information gathered. words dilated convolution operators filter different ranges using different dilation factors. compared using larger convolution windows using filter dilation pros lower computation cost cons unequal convolutional coverage input space. observation indicates boosting position awareness dilation mechanism stronger effect encoder decoder. simple inner-product attention correlates tensors position-wise. given tensors stands depth according attention mechanism computes feature vector similarities position re-scales according depth cross-attention often used \"encoder-decoder attention\" layers comes previous decoder layer encoded input i.e. output encoder. allows every position decoder attend positions input sequence. self-attention used input encoding target encoding come place output previous layer encoder decoder. self-attention layer encoder allows position attend positions previous layer encoder; similarly self attention layer decoder allow position attend positions decoder including position. prevent leftward information flow decoder preserve autoregressive property masking values input softmax correspond illegal positions necessary. strengthen positional relationship convolution based sequence-to-sequence learning apply cross-attention self-attention multiple times. experienced certain accuracy gain. order capture richer sequential position information position-wise relationships inputs targets improved accuracy based sequence-to-sequence learning follow design considerations impact position-sensitivity accuracy sequence-tosequence learning varies encoding process decoding process; result context specific convolution boxes needed applying position-sensitive mechanisms. intuitively inputs encoded sequences dealt completely populated thus sensitive enhanced position encoding. however decoding partially generated targets pads space-fillers mechanisms repeated position encoding would ineffective even noisy. context sensitivity mechanisms capturing position information explained similarly. posenet architecture built using tensortensor library extending slicenet model. follow conceptual encoder-decoder structure encoder maps input sequence representations sequence continuous hidden representations there decoder generates output sequence element time. step model auto-regressive consuming previously generated elements additional input generating next. architecture realizes overall encoder-decoder structure using stacked convolution boxes point-wise fully connected layers shown left right halves figure respectively. however convolution boxes customized differently encoder decoder. encoder composed stack layers. layer convolution boxes residual links simple position-wise fully connected feed-forward net. sub-layer function employ residual connection followed layer normalization i.e. produce norm). addition layer begins position encoding ends positionwise feed-forward allow strengthen position-sensitivity model repeated layers. also choose invoke dilation convolutions provided tensortensor library encoding position-wise correlate distant elements. worth noting repeat position-encoding dilation convolution encoding decoding reasons explained. model follows convolutional autoregressive structure introduced slicenet bytenet wavenet pixelcnn inputs embedded encoded decoder auto-regressively generates element output. every step autoregressive decoder produces output prediction given encoded inputs stack decoder layers. cross-attention allows decoding step coding step stack decoder layers. inputs repeatedly applied layer. encoder attend encoded-inputs repeatedly applied layer. encoder decoder layer ends position-wise feed-forward net. decoder layer also decoder layer ends position forward net. decoder layer also convolution boxes residual links wise fully connected feed-forward network. masking used prevent positions attending subsequent positions. mask asking used prevent positions attending subsequent positions. mask asking used prevent positions attending subsequent positions. mask output embeddings ensure prediction position depend offset output embeddings ensure prediction position depend known outputs positions less position. positions less position. summary capturing sequential position information position-wise relationships inputs targets posenet treats convolution boxes encoder decoder differently; words encoder decoder employ context specific convolution boxes involve position-sensitive mechanisms different ways. encoder stack position encoding position-wise feed-forward applied beginning ending layer repeatedly convolutions dilated sensitivity distant positions. decoder stacks cross-attention used layer repeatedly position encoding optionally applied once. chose dilated convolution decoder step-by-step decoding process outputs pads shift thus less sensitive dilation. reason apply optionally apply without repeating every layer position encoding case less effect even adds noise. please also note layer cross-attention place convolution boxes. enhanced parallelism and/or reduced parameters mechanisms multi-head attention depth-wise convolution introduced common characterized splitting channels input several non-overlapping segments performing regular attention spatial convolution segment independently concatenating resulting feature maps along channel axis. details mechanisms found tensorflow specifications. work take advantage them. carry experiments gnu/linux ..--generic -ubuntu memory using nvidia geforce cuda python.. tensorflow.. tensortensor-... study focus follows issues model trained evaluated english-to-german english-tofrench translation tasks using benchmark data translate_ende_wmtk translate_enfr_wmtk. sizes sample data measured disk ende en-fr. experiments implemented using tensorflow framework tensortensor library also leveraged convolution attention mechanisms described related work convolution based sequence-to-sequence combination several position sensitivity strengthen mechanisms repeatedly imposing timing signal selectively apply dilation appropriate parameterized convolution-based self-attention etc; certain position sensitivity strengthen mechanisms effective accuracy enhancement applied encoding including input encoding target encoding rather decoding. intermediate training states checkpointed tensorflow framework; along checkpoint corresponding evaluation results logged. attached partial evaluation results last checkpoints training en-de translation model appendix training en-fr translation model appendix average bleu scores approximately consistent measured additional checkpoints sing model batch-size using en-de translation task achieved approximate bleu scores training steps; en-fr translation task achieved approximate bleu scores training steps translations compared related work listed table below. en-de translation task --------------------------------------------------------------------------model --------------------------------------------------------------------------bytenet gnmt convss gnmt ensemble convss ensemble transformer transformer slicenet slicenet --------------------------------------------------------------------------- posenet --------------------------------------------------------------------------table performance models en-de en-fr translation tasks benchmark data translate_ende_wmtk translate_enfr_wmtk compared latest published results; bleu averages scores measured last checkpoints goal providing generalized efficient deep-learning framework motivated explore possibility using universal building blocks. already superior track-record audio image text learning particularly focus potential sequence-to-sequence computations involved easily parallelizable less history sensitive. therefore enhancing sequential order awareness position-sensitivity support sequence transformation. work introduce architecture posenet characterized applying position-sensitive mechanisms position encoding self-attention cross-attention dilation convolution position-wise feed-forward residual selectively encoder decoder maximizing effects. notable feature posenet asymmetric treatment position information encoder decoder. turn common convolution boxes specific ones depending used different sub-layers capturing context specific sequence oriented information. experiments show strengthen position-sensitivity posenet capable improving accuracy convolutional sequence-to-sequence learning achieving around approximate bleu scores approximate bleu scores english-to-german english-to-french translation tasks respectively. kyunghyun bart merrienboer caglar gulcehre fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. corr abs/. arxiv. junyoung chung çaglar gülçehre kyunghyun yoshua bengio. empirical evaluation gated recurrent neural networks sequence modeling. corr abs/. grammars. proc. naacl jonas gehring michael auli david grangier denis yarats yann dauphin. convolutional sequence sequence learning. arxiv preprint arxiv. kaiming xiangyu zhang shaoqing jian sun. deep residual learning image recognition. proceedings ieee conference computer vision pattern recognition pages noam shazeer azalia mirhoseini krzysztof maziarz andy davis quoc geoffrey hinton jeff dean. outrageously large neural networks sparsely-gated mixture-of-experts layer. arxiv preprint arxiv. aäron oord sander dieleman heiga karen simonyan oriol vinyals alex graves kalchbrenner andrew senior koray kavukcuoglu. wavenet generative model audio. corr abs/. aaron oord kalchbrenner lasse espeholt oriol vinyals alex graves conditional image generation pixelcnn decoders. advances neural information processing systems pages yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey jeff klingner apurva shah melvin johnson xiaobing lukasz kaiser stephan gouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wang cliff young jason smith jason riesa alex rudnick oriol vinyals greg corrado macduff hughes jeffrey dean. google’s neural machine translation system bridging human machine translation. corr abs/. yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey google’s neural machine translation system bridging human machine translation. arxiv preprint arxiv. infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowfinished evaluation infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_ende_wmtk/neg_log_perplexity loss metrics-translate_ende_wmtk/rouge__fscore metrics-translate_ende_wmtk/accuracy metrics-translate_ende_wmtk/rouge_l_fscore metrics-translate_ende_wmtk/approx_bleu_score metrics-translate_ende_wmtk/accuracy_top infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss infotensorflowvalidation metrics-translate_enfr_wmtk/accuracy metrics-translate_enfr_wmtk/approx_bleu_score metrics-translate_enfr_wmtk/accuracy_top metrics-translate_enfr_wmtk/rouge_l_fscore metrics-translate_enfr_wmtk/neg_log_perplexity metrics-translate_enfr_wmtk/rouge__fscore loss", "year": 2017}