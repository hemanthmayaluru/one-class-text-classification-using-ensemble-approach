{"title": "The Combined Technique for Detection of Artifacts in Clinical  Electroencephalograms of Sleeping Newborns", "tag": ["cs.NE", "cs.AI", "cs.LG"], "abstract": "In this paper we describe a new method combining the polynomial neural network and decision tree techniques in order to derive comprehensible classification rules from clinical electroencephalograms (EEGs) recorded from sleeping newborns. These EEGs are heavily corrupted by cardiac, eye movement, muscle and noise artifacts and as a consequence some EEG features are irrelevant to classification problems. Combining the polynomial network and decision tree techniques, we discover comprehensible classification rules whilst also attempting to keep their classification error down. This technique is shown to outperform a number of commonly used machine learning technique applied to automatically recognize artifacts in the sleep EEGs.", "text": "abstract—in paper describe method combining polynomial neural network decision tree techniques order derive comprehensible classification rules clinical electroencephalograms recorded sleeping newborns. eegs heavily corrupted cardiac movement muscle noise artifacts consequence features irrelevant classification problems. combining polynomial network decision tree techniques discover comprehensible classification rules whilst also attempting keep classification error down. technique shown outperform number commonly used machine learning technique applied automatically recognize artifacts sleep eegs. lectroencephalograms representing weak potentials invoked brain activity give eeg-experts objective information analysis classification although eegs noise nonstationary signals varying patient large range amplitudes frequencies eegs used assist clinicians diagnose diseases apnea alzheimer dementia schizophrenia make reliable decisions clinicians properly separate neural activity patients artifacts caused electrode noise movement cardiac muscle activities. methods independent component analysis regression methods principle component analysis threshold technique comparing high frequency activity brief segments local background activity calculated window predefined length similarly outlying methods technique discards brief -second segments power high frequency band threshold dependent average value calculated window. methods suggested classification clinical eegs based fully connected feed-forward neural network users properly predefine suitable network structure well learning method fitting synaptic weights network. although fnns learn classify eegs well corruptions eegs still lead ambiguous results underlining brain muscle activities share characteristics wave shape frequencies meantime important classification models comprehensible medical experts large number synaptic connections contrast fnns predefined structure group method data handling allows induce wellsuited neural networks data gmdh algorithms generate multilayer neural network step-by-step growing layers neurons. network grows predefined criterion reaches minimum located near global one. criterion based cross-validation error function assuming training validation data subsets. resultant classification model described concise neurons given transfer function example polynomial one. derive classification rules data could directly apply decision tree technique exploits greedy hill-climbing strategy technique capable partitioning data well however presence irrelevant noise features derive classification rules poor generalization ability drawback technique particularly overcome using pruning strategies described paper describe combined technique developed learning artifact recognition clinical eegs recorded sleeping newborns. research fruitful machine learning pattern recognition methods induce rules automated recognition artifacts compare performances. within techniques commonly used analyzing sleep eegs frequency domain inducing rules channels besides eeg. however experts labeling segments used additional information coming channels useful visual recognition artifacts. cardiac movement muscle noise artifacts visually recognizable eegs labeled. within research also evaluate well discovered rules recognize artifacts eegs recorded newborns background neural activity varies sleep hours. variations heavily affect accuracy artifact recognition research however average estimations background neural activity suggested attempt learning recognition rule exploiting spectral features calculated current segment. framework technique first learn gmdh-type neural network given training data. network nearly minimal number neurons involves features make important contribution classification patterns. using selected features training examples correctly classified induce appropriate result derive comprehensible classification rule whilst also attempting keep classification error down. section describe classification problem clinical data used experiments. section briefly describe gmdh algorithms present learning algorithm. sections present induction technique compare performance approach clinical eegs. finally refer related work briefly discuss obtained results. referring recording newborns eegs analyzed particular attention presence type movements facial movements respiration sucking crying etc. extracerebral monitors needed routine recordings including least electrooculogram respiration rate measurement electrocardiogram reduced number scalp electrodes generally never -channel recording applicable. active sleep antecedent rapid movement sleep usually irregular respiratory patterns interspersed brief episodes often precede clusters movements. contrary adult physiology prominent subtle motor activity especially face accompanies state. experiments clinical eegs recorded sleeping newborns standard channels sampled eegs transformed frequency domain using fast fourier transform described spectral features calculated -second segments frequency bands subdelta delta theta alpha beta beta additionally band values relative absolute powers calculated. values calculated channels well total number features values features normalized zero mean unit variance. using additional channels eeg-experts recognized cardiac movement muscle noise artifacts labeled segments recorded newborns aged weeks. first experiment eegs recorded newborns available learning testing classification rule. training testing eegs contain labeled segments artifact rates respectively. note segments labeled eeg-expert. second experiment records available records containing segments randomly selected training remaining records containing segments used testing. artifact rates training testing datasets respectively. segments labeled experienced eeg-experts applied subjective strategies artifact recognition. experiments identify records labeled experts. taking account high artifact rate differences strategies experts expect vector class labels much noise first experiment. experiments focus mainly comparing performance technique commonly used machine learning methods applied artifact recognition clinical presented frequency domain. paper study methods analyze additional channels time domain. idea behind method classification combine gmdh-type neural network decision tree techniques. first technique used induce well-suited neural network involves relevant features allows find misclassified training examples. using decision tree technique derive accurate classification rule training data cleaned irrelevant features misclassified examples. cleaning training data presented relevant variables boundaries circumstances expect increase chance find section briefly describe gmdh algorithms capable inducing well-suited polynomial neural networks data. induced gmdh-type networks generalize well size complexity nearly minimal. gmdh algorithms gmdh-type polynomial networks multilayered feed-forward networks consisting so-called supporting neurons least inputs transfer function neurons described short-term polynomials example nonlinear polynomial using supporting neurons gmdh algorithm builds generation layer candidate-neurons selects best them. candidate-neurons selected so-called exterior criterion evaluates generalization ability neurons unseen data defined validation data. user predefine exterior criterion well number neurons selected layer. giving large user increases chance find global minimum cross-validation error however large values increases computational expenses. practice gmdh algorithms perform enough well equal number input variables best performance achieved layers gmdh-type networks grow one-by-one. first layer candidate-neurons connected inputs next layer connected outputs neurons selected previous layer. gmdh algorithms allow also combining input nodes neurons taken previous layers validation data used control complexity number layers gmdh-type network learning. fitting weights conventional gmdh algorithms exploit least square method provides effective estimates weights training data gaussian distributed real-world data gaussian distribution unrealistic estimations become biased used cases avoid problem make estimations weights without unrealistic assumptions distribution function training data; learning method described section dependent well neuron classifies unseen data therefore value expected large neurons poor generalization ability small neurons generalize well. values calculated candidateneurons layer gmdh sorts ascending order first neurons provide best classification accuracy. minimal value exterior criterion used check following stopping rule decreases rapidly first layers gmdh-type network relatively slowly near optimal number layers increasing number layers causes increasing over-fitting thus value number layers network increases one-by-one stopping rule layer subsequently take desired gmdh-type network nearly optimal complexity layer. distribution real-world data lead biased estimations neuron weights. however learning algorithm dependent distribution training data. describe method. large-scale data search threshold training examples take long time. reduce computational expenses applied technique draws random values given number attempts. giving rational number attempts achieve good performance acceptable time. apply technique clinical eegs. given learning rate euclidean norm. desired estimation weights achieved finite number steps learning rate lies proof experiments best performance obtained ratio nb/n learning rate initial weights distributed gaussian case number exceed steps. idea behind algorithm used experiments rule extraction similar algorithm described first define training subsets consisting examples assigned classes number training examples correctly classified gmdh-type network. network exploits input variables presenting variables relevant classification problem. also initialize decision tree define procedure find_node invoked parameters. procedure searches input variable threshold provide best partition subsets node involving variable threshold added procedure find_node section describe experiments aimed evaluating performance technique machine learning methods commonly used eegs. experiments carried labeled eegs recorded several newborns described section first eegs second eegs. experiments compared machine learning techniques k-nearest neighbor standard gmdh described section polynomial neural network combined techniques. artifact rate eegs additionally performance evaluated sensitivity specificity classifiers. sensitivity calculated specificity number patterns classified true positive true negative false positive false negative respectively. performance calculated positive patterns associated artifacts negative normal segments. searching parameters splitting nodes used technique described tests given number values drawn uniform distribution ranged minimal maximal values feature tested relpowthetac relative power theta relpowtheta relative power theta abspowthetac absolute power theta relpowalpthac relative power alpha abspowalpha absolute power alpha defining transfer function polynomial function arguments connected either outputs previous neurons features listed above best comprehensively described following seven polynomials following technique used induced pnns remove irrelevant features misclassified examples training data. cleaned data used induce described section runs performance number splitting nodes ranging training fnns used standard technique based principal component analysis fast levenberg-marquardt back-propagation learning algorithm provided matlab. fnns given number hidden neurons randomly initialized weights trained times. inducing gmdh-type networks used modified random algorithm described connections different layers neurons. algorithm takes random pair neurons creates neuron added network values criterion calculated taken neurons respectively. growth network terminates prespecified number failed attempts improving performance; number specified equal gmdh-type networks well pnns used transfer function equal first experiment used containing labeled segments training containing segments testing. artifacts rates eegs respectively. table lists mean confidence interval sensitivity specificity performance calculated gmdh well pnn&dt testing eeg. inducing used pruning strategy cutting nodes splitting fewer data points training data. resultant correctly classified testing segments. number nodes applying standard neural network technique found fnns exploiting hidden neurons principal components provided best performance runs fnns correctly classified testing data. induced pnn&dt technique almost conventional technique. meantime outperform confidence interval significance conclude pnn&dt technique performs data better technique. observing results table conclude technique certainly outperforms neural-network techniques sleep eegs. however analyzing induced described above exploit feature abspowbeta presenting power high frequency band mentioned testing feature abspowbeta band without information background neural activity sleeping newborns cannot perform enough well. correction techniques focus mainly removing ocular artifacts removing artifacts caused muscle activity cardiac signals electrode noise. regression methods removing muscle noise impractical experiment shows removing misclassified training examples irrelevant features could reduce size keep classification error down. average size induced technique decreased average performance slightly increased easily interpreted experts. note first experiment artifacts rates eegs used training testing relative small. eegs labeled expert applying strategy artifact recognition. would interesting check performance induced eegs recorded patients labeled eeg-viewers. performance induced evaluated segments recorded newborns. values sensitivity specificity respectively. derived able classify eegs recorded patients well. means classification model dependent patient specifics influence might diminished inducing large records. second experiment used much data training testing examples recorded newborns described section artifact rates eegs also much higher training testing data. inducing used searching strategy drawing random values uniform distribution splitting nodes containing fewer data points training data. resultant correctly classified testing segments number splitting nodes several methods proposed removing eye-movement artifacts based regression time domain however time domain removing artifacts tends overcompensate blink artifacts regression frequency domain account frequency-dependent transfer function differences eeg. regression methods time frequency domains depend regressing channel. method artifact removal proposed using spatiotemporal dipole model requires priori assumptions number dipoles saccade blink movements. technique proposed removing ocular artifacts using principal component analysis. corrected data could obtained removing corrupted components simple inverse computation. using technique ocular artifacts removed effectively regression using spatiotemporal dipole models. makeig proposed approach analysis data based independent component analysis algorithm used separate neural activity muscle blink artifacts spontaneous data. methods based assumptions signals recorded scalp mixtures time courses temporally independent cerebral artifact sources potentials arising different parts brain scalp body summed linearly electrodes propagation delays negligible. corrected signals derived eliminating contributions artifact sources. several methods suggested automated analysis eegs based neural networks deal artifacts system identifies type corruptions characterizes ocular muscle artifacts. valuable spectral features eegs extracted using parametric modeling cross-correlation. breidbach classified eegs recorded sleeping newborns using including inputs output neurons sigmoid activation function. learning algorithm used aims maximize euclidean distance output vectors belonging different classes. analyzing clusters space output variables discovered correlation neuron outputs risk groups conclude neural network five inputs produce better classification accuracy. rule extraction techniques described prune synaptic weights retrain fnns. strategy based trade-off complexity classification accuracy extracted rules additionally computationally expensive. rule extraction method based successive regularization retraining ffns. resultant rules extracted given parameters method dependent gmdh suggested learn polynomial models nearly minimal complexity data models comprehensively described shortterm polynomials users find observable fully connected neural-network classifiers. although fully connected well polynomial neural networks learn classify eegs well classifiers cannot comprehensible clinicians. hand rule extraction decision tree techniques able produce comprehensible rules commonly based trade-off complexity classification accuracy rules. contrary approach combine polynomial neural network decision tree techniques able keeping classification error down. using technique paper learnt rule automated recognition cardiac movement muscle artifacts sleep eegs presented frequency domain. recognition assumed rule exploiting features calculated current segment additional information coming channels outside used experts label artifacts. result discovered rule easily interpreted decision tree testing power high frequency band. analogous feature tested recognizing muscle artifacts sleep using threshold technique additionally technique evaluates background neural activity minute window adjusted adult eegs. however experiments information used learning rule. first practical result research discovered recognition rule comprehensible eeg-experts rule matches well rule described second practical performance commonly used machine learning methods sleep eegs without using additional information coming channels besides eeg. final point rule learnt automated recognition types artifacts including cardiac movement muscle electrode noise visually recognizable eegexperts. comparing classification accuracy testing data seen technique outperforms commonly used machine learning methods. however large variation eegs sleeping newborns could achieve high accuracy artifact recognition without additional information background neural activity described n.l. nikolaev automated discovery polynomials inductive genetic programming principles data mining knowledge discovery zutkow ranch springer berlin worked associate professor computer science penza state university later research fellow university jena germany university exeter research interests include machine learning pattern recognition neural network methods applications. lecturer biology university hamburg later worked research associate laboratory headed prof. basar university lübeck. also head theorielabor university jena. research interests involve phylogeny evolution arthropoda structure function electroencephalogram biosemiotics theoretical concepts biology. authors grateful frank pasemann enlightening discussions joachim frenzel burkhart scheidt clinic university jena clinical records jonathan fieldsend university exeter useful comments. makeig bell jung sejnowski independent component analysis electroencephalographic data advances neural information processing systems touretzky mozer hasselmo cambridge press vol. riddington ifeachor allen hudson mapps fuzzy expert system interpretation neural networks expert systems medicine healthcare ifeachor rosén plymouth england anderson devulapalli stolz signal classification different signal representations neural networks signal processing girosi makhoul manolakos wilson ieee service centre piscataway galicki witte dörschel doering eiselt grießbach common optimization adaptive preprocessing units neural network learning period. application pattern recognition neural networks breidbach holthausen scheidt frenzel analysis data room sudden infant death risk patients theory biosciences james kobayashi lowe seizure detection selforganizing feature artificial neural network medicine biology malmgren borga niklasson goteborg sweden springer-verlag t.-p. jung makeig humphries t.-w. mckeown iragui sejnowski removing electroencephalographic artifacts blind source separation psychophysiology whitton moldofsky spectral method removing eye-movement artifacts electroencephalography clinical neurophysiology", "year": 2005}